{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    " <img src=\"http://www.di.uoa.gr/themes/corporate_lite/logo_en.png\" title=\"Department of Informatics and Telecommunications - University of Athens\" align=\"center\" /> \n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\"> \n",
    "  <font size=\"4\"><b>Bachelor Thesis</b> </font>\n",
    "</div>\n",
    "<br>\n",
    "<div align=\"center\"> \n",
    "  <font size=\"5\">\n",
    "      <b>Entity Resolution in Dissimilarity Spaces  <br></b> \n",
    "    </font>\n",
    "     <br>\n",
    "     <font size=\"3\">\n",
    "        Implementation notebook     \n",
    "    </font>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\"> \n",
    "    <font size=\"4\">\n",
    "         <b>Konstantinos Nikoletos, BS Student</b>\n",
    "     </font>\n",
    "</div>\n",
    "<br>\n",
    "<div align=\"center\"> \n",
    "    <font size=\"4\">\n",
    "     <b> Dr. Alex Delis</b>,  Professor NKUA <br> \n",
    "     <b> Dr. Vassilis Verikios</b>, Professor Hellenic Open University\n",
    "    </font>\n",
    "</div>\n",
    "<br>\n",
    "<div align=\"center\"> \n",
    "    <font size=\"2\">Athens</font>\n",
    "</div>\n",
    "<div align=\"center\"> \n",
    "    <font size=\"2\">January 2021 - Ongoing</font>\n",
    "</div>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Implementation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Install components__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install editdistance\n",
    "!pip install pandas_read_xml\n",
    "!pip install requests\n",
    "!pip install python-igraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Import libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import editdistance\n",
    "import string\n",
    "import sklearn\n",
    "import pandas_read_xml as pdx\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import math\n",
    "import os\n",
    "import scipy.special as special\n",
    "import igraph\n",
    "import networkx as nx\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from scipy.spatial.distance import directed_hausdorff,hamming\n",
    "from scipy.stats._stats import _kendall_dis\n",
    "from scipy.stats import spearmanr,kendalltau,pearsonr,kruskal,mannwhitneyu\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.metrics.distance import jaro_similarity,jaro_winkler_similarity,jaccard_distance\n",
    "from sklearn.metrics import jaccard_score,accuracy_score,auc,f1_score,recall_score,precision_score,classification_report\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse\n",
    "from scipy import stats \n",
    "from scipy.spatial.distance import euclidean,hamming,jaccard\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.metrics import ndcg_score\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA \n",
    "from numpy.linalg import svd\n",
    "\n",
    "plt.style.use('seaborn-white') # plot style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RankedWTAHash:\n",
    "\n",
    "    def __init__(self, max_numberOf_clusters, max_dissimilarityDistance, windowSize, \n",
    "                 number_of_permutations=1, min_numOfNodes = 2, jaccard_withchars =True,\n",
    "                 distanceMetricEmbedding = 'euclidean', metric = 'kendal', similarityVectors='ranked', \n",
    "                 distanceMetric = 'edit', prototypesFilterThr = None, ngramms = None, \n",
    "                 similarityThreshold = None, maxOnly = None, earlyStop=0, \n",
    "                 verboseLevel=0, rbo_p = 0.7):\n",
    "        '''\n",
    "          Constructor\n",
    "        '''\n",
    "        self.max_numberOf_clusters = max_numberOf_clusters\n",
    "        self.pairDictionary = dict()\n",
    "        self.max_dissimilarityDistance = max_dissimilarityDistance\n",
    "        self.windowSize = windowSize\n",
    "        self.S_set = None\n",
    "        self.S_index = None\n",
    "        self.similarityThreshold = similarityThreshold\n",
    "        self.maxOnly = maxOnly\n",
    "        self.metric = metric\n",
    "        self.min_numOfNodes = min_numOfNodes\n",
    "        self.similarityVectors = similarityVectors\n",
    "        self.number_of_permutations = number_of_permutations\n",
    "        self.distanceMetric = distanceMetric\n",
    "        self.distanceMetricEmbedding = distanceMetricEmbedding\n",
    "        self.ngramms = ngramms\n",
    "        self.jaccard_withchars =  jaccard_withchars\n",
    "        self.prototypesFilterThr = prototypesFilterThr\n",
    "        self.earlyStop = earlyStop\n",
    "        self.selectionVariance = None\n",
    "        self.numOfComparisons = 0\n",
    "        self.verboseLevel = verboseLevel\n",
    "        self.rbo_p = rbo_p\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "          Fit the classifier from the training dataset.\n",
    "          Parameters\n",
    "          ----------\n",
    "          X : Training data.\n",
    "          \n",
    "          Returns\n",
    "          -------\n",
    "          self : The fitted classifier.\n",
    "        \"\"\"\n",
    "        print(\"\\n#####################################################################\\n#     .~ RankedWTAHash with Vantage embeddings starts training ~.   #\\n#####################################################################\\n\")\n",
    "\n",
    "        if isinstance(X, list):\n",
    "            input_strings = X\n",
    "        else:\n",
    "            input_strings = list(X)\n",
    "\n",
    "        self.initialS_set = np.array(input_strings,dtype=object)\n",
    "        self.S_set = np.array(input_strings,dtype=object)\n",
    "        if self.distanceMetric == 'jaccard' and self.jaccard_withchars == False:\n",
    "            for i in range(0,len(input_strings)):\n",
    "                self.S_set[i] = set(nltk.ngrams(nltk.word_tokenize(self.S_set[i]), n=self.ngramms))\n",
    "        elif self.distanceMetric == 'jaccard' and self.jaccard_withchars == True:\n",
    "            for i in range(0,len(input_strings)):\n",
    "                self.S_set[i] = set(nltk.ngrams(self.S_set[i], n=self.ngramms))\n",
    "\n",
    "        self.S_index = np.arange(0,len(input_strings),1)\n",
    "        \n",
    "        if self.verboseLevel > 1:\n",
    "            print(\"\\n\\nString positions are:\")\n",
    "            print(self.S_index)\n",
    "            print(\"\\n\")\n",
    "\n",
    "        print(\"###########################################################\\n# > 1. Prototype selection phase                          #\\n###########################################################\\n\")\n",
    "        print(\"\\n-> Finding prototypes and representatives of each cluster:\")\n",
    "        prototypes_time = time.time()\n",
    "        self.prototypeArray,self.selected_numOfPrototypes = self.Clustering_Prototypes(self.S_index,self.max_numberOf_clusters, self.max_dissimilarityDistance, self.pairDictionary)\n",
    "        self.embeddingDim = self.prototypeArray.size\n",
    "        \n",
    "        if self.verboseLevel > 0:\n",
    "            print(\"\\n- Prototypes selected:\")\n",
    "            print(self.prototypeArray)\n",
    "            heatmapData = []\n",
    "            for pr in self.prototypeArray:\n",
    "                print(pr,\" -> \",self.initialS_set[pr])\n",
    "                heatmapData.append(self.S_set[pr])            \n",
    "            if self.selected_numOfPrototypes > 2:\n",
    "                self.selectionVariance = myHeatmap(self.prototypeArray,self.metric,self.dissimilarityDistance)\n",
    "                print(\"\\n- Mean variance in prototype selection: \", self.selectionVariance)\n",
    "\n",
    "        print(\"\\n- Final number of prototypes: \",self.selected_numOfPrototypes )\n",
    "        prototypes_time = time.time() - prototypes_time\n",
    "        print(\"\\n# Finished in %.6s secs\" % (prototypes_time))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        if self.earlyStop==1:\n",
    "            return self\n",
    "\n",
    "        print(\"###########################################################\\n# > 2. Embeddings based on the Vantage objects            #\\n###########################################################\\n\")\n",
    "        print(\"\\n-> Creating Embeddings:\")\n",
    "        embeddings_time = time.time()\n",
    "        self.Embeddings = self.CreateVantageEmbeddings(self.S_index, self.prototypeArray, self.pairDictionary)\n",
    "        print(\"- Embeddings created\")\n",
    "       \n",
    "        if self.verboseLevel > 0:\n",
    "            print(self.Embeddings)\n",
    "            PCA_SpaceVisualization(self.Embeddings, self.prototypeArray)        \n",
    "        \n",
    "        embeddings_time = time.time() - embeddings_time\n",
    "        print(\"\\n# Finished in %.6s secs\" % (embeddings_time))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        if self.earlyStop==2:\n",
    "            return self\n",
    "\n",
    "        print(\"###########################################################\\n# > 3. WTA Hashing                                        #\\n###########################################################\\n\")\n",
    "        print(\"\\n-> Creating WTA Buckets:\")\n",
    "        wta_time = time.time()\n",
    "        self.HashedClusters,self.buckets,self.rankedVectors = self.WTA(self.Embeddings, self.windowSize, self.number_of_permutations)\n",
    "        \n",
    "        if self.verboseLevel > 0:\n",
    "            print(\"- WTA buckets: \")\n",
    "            for key in self.buckets.keys():\n",
    "                print(key,\" -> \",self.buckets[key])\n",
    "        \n",
    "        print(\"\\n- WTA number of buckets: \", len(self.buckets.keys()))\n",
    "        \n",
    "        if self.verboseLevel > 1:\n",
    "            print(\"\\n- WTA RankedVectors after permutation:\")\n",
    "            print(self.rankedVectors)\n",
    "\n",
    "        if self.verboseLevel > 0:\n",
    "            if self.similarityVectors == 'ranked':\n",
    "                WTA_PCA_SpaceVisualization_3D(self.rankedVectors, self.prototypeArray, self.HashedClusters, withgroundruth=True, groundruth=labels_groundTruth, title='PCA visualization GroundTruth')\n",
    "            elif self.similarityVectors == 'initial':\n",
    "                WTA_PCA_SpaceVisualization_3D(self.Embeddings, self.prototypeArray, self.HashedClusters, withgroundruth=True, groundruth=labels_groundTruth, title='PCA visualization GroundTruth')\n",
    "\n",
    "        wta_time = time.time() - wta_time\n",
    "        print(\"\\n# Finished in %.6s secs\" % (wta_time))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        if self.earlyStop==3:\n",
    "            return self\n",
    "\n",
    "        print(\"###########################################################\\n# > 4. Similarity checking                                #\\n###########################################################\\n\")\n",
    "        print(\"\\n-> Similarity checking:\")\n",
    "\n",
    "        similarity_time = time.time()\n",
    "\n",
    "        if self.similarityVectors == 'ranked':\n",
    "            self.mapping,self.mapping_matrix = self.SimilarityEvaluation(self.buckets,self.rankedVectors,self.similarityThreshold,maxOnly=self.maxOnly, metric=self.metric)\n",
    "        elif self.similarityVectors == 'initial':\n",
    "            self.mapping,self.mapping_matrix = self.SimilarityEvaluation(self.buckets,self.Embeddings,self.similarityThreshold,maxOnly=self.maxOnly, metric=self.metric)\n",
    "        else:\n",
    "            warnings.warn(\"similarityVectors: Available options are: ranked,initial\")\n",
    "        \n",
    "        if self.verboseLevel > 1:\n",
    "            print(\"- Similarity mapping in a matrix\")\n",
    "            print(self.mapping_matrix)\n",
    "        \n",
    "        if self.verboseLevel > 0:\n",
    "            print(\"\\n- Total number of comparisons made: \", self.numOfComparisons)\n",
    "            print(\"\\n- Total number of comparisons of same objects: \", self.sameObjectsCompared)\n",
    "            print(\"\\n- Total number of comparisons of same objects with success: \", self.sameObjectsComparedSuccess)\n",
    "            print(\"\\n- Total number of comparisons of different objects with success: \", self.diffObjectsComparedSuccess)\n",
    "        \n",
    "        similarity_time = time.time() - similarity_time\n",
    "        print(\"\\n# Finished in %.6s secs\" % (similarity_time))\n",
    "        print(\"\\n#####################################################################\\n#                           .~  End  ~.                             #\\n#####################################################################\\n\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def dissimilarityDistance(self, str1,str2,verbose=False):\n",
    "        if self.verboseLevel > 2:\n",
    "            print(\"-> \", self.initialS_set[str1])\n",
    "            print(\"--> \", self.initialS_set[str2])\n",
    "\n",
    "        if ((str1,str2) or (str2,str1))  in self.pairDictionary.keys():\n",
    "            return self.pairDictionary[(str1,str2)]\n",
    "        else:\n",
    "            if self.distanceMetric == 'edit':\n",
    "                distance = editdistance.eval(self.S_set[str1],self.S_set[str2])\n",
    "            elif self.distanceMetric == 'jaccard':\n",
    "                distance = jaccard_distance(self.S_set[str1],self.S_set[str2])\n",
    "            else:\n",
    "                warnings.warn(\"Available metrics for space creation: edit, jaccard \")\n",
    "            self.pairDictionary[(str2,str1)] = self.pairDictionary[(str1,str2)] = distance\n",
    "            \n",
    "            if self.verboseLevel > 2:\n",
    "                print(distance)\n",
    "            \n",
    "            return distance\n",
    "\n",
    "    #####################################################################\n",
    "    # 1. Prototype selection algorithm                                  #\n",
    "    #####################################################################\n",
    "\n",
    "    '''\n",
    "    Clustering_Prototypes(S,k,d,r,C) \n",
    "    The String Clustering and Prototype Selection Algorithm\n",
    "    is the main clustering method, that takes as input the intial strings S, \n",
    "    the max number of clusters to be generated in k,\n",
    "    the maximum allowable distance of a string to join a cluster in var d\n",
    "    and returns the prototype for each cluster in array Prototype\n",
    "    '''\n",
    "    def Clustering_Prototypes(self,S,k,d,pairDictionary,verbose=False):\n",
    "\n",
    "        # ----------------- Initialization phase ----------------- #\n",
    "        i = 0\n",
    "        j = 0\n",
    "        C = np.empty([S.size], dtype=int)\n",
    "        r = np.empty([2,k],dtype=object)\n",
    "\n",
    "        Clusters = [ [] for l in range(0,k)]\n",
    "\n",
    "        for i in tqdm(range(0,S.size,1)):     # String-clustering phase, for all strings\n",
    "            while j < k :       # iteration through clusters, for all clusters\n",
    "                if r[0][j] == None:      # case empty first representative for cluster j\n",
    "                    r[0][j] = S[i]   # init cluster representative with string i\n",
    "                    C[i] = j         # store in C that i-string belongs to cluster j\n",
    "                    Clusters[j].append(S[i])\n",
    "                    break\n",
    "                elif r[1][j] == None and (self.dissimilarityDistance(S[i],r[0][j]) <= d):  # case empty second representative\n",
    "                    r[1][j] = S[i]                                             # and ED of representative 1  smaller than i-th string\n",
    "                    C[i] = j\n",
    "                    Clusters[j].append(S[i])\n",
    "                    break\n",
    "                elif (r[0][j] != None and r[1][j] != None) and (self.dissimilarityDistance(S[i],r[0][j]) + self.dissimilarityDistance(S[i],r[1][j])) <= d:\n",
    "                    C[i] = j\n",
    "                    Clusters[j].append(S[i])\n",
    "                    break\n",
    "                else:\n",
    "                    j += 1\n",
    "            i += 1\n",
    "\n",
    "        # ----------------- Prototype selection phase ----------------- #\n",
    "\n",
    "        Projections = np.empty([k],dtype=object)\n",
    "        Prototypes = np.empty([k],dtype=int)\n",
    "        sortedProjections = np.empty([k],dtype=object)\n",
    "        Projections = []\n",
    "        Prototypes = []\n",
    "        sortedProjections = []\n",
    "\n",
    "        if self.verboseLevel > 2:\n",
    "            print(\"- - - - - - - - -\")\n",
    "            print(\"Cluster array:\")\n",
    "            print(C)\n",
    "            print(\"- - - - - - - - -\")\n",
    "            print(\"Represantatives array:\")\n",
    "            print(r)\n",
    "            print(\"- - - - - - - - -\")\n",
    "            print(\"Clusters:\")\n",
    "            print(Clusters)\n",
    "            print(\"- - - - - - - - -\")\n",
    "            print(\"k:\")\n",
    "            print(k)\n",
    "            print(\"- - - - - - - - -\")\n",
    "\n",
    "        new_numofClusters = k\n",
    "        prototype_index = 0\n",
    "        for j in range(0,k,1):\n",
    "            \n",
    "            apprxDistances = self.ApproximatedProjectionDistancesofCluster(r[1][j], r[0][j], j, Clusters[j], pairDictionary)\n",
    "            \n",
    "            if apprxDistances == None:\n",
    "                new_numofClusters-=1\n",
    "                continue\n",
    "            \n",
    "            Projections.append(apprxDistances)\n",
    "            sortedProjections.append({new_numofClusters: v for new_numofClusters, v in sorted(Projections[prototype_index].items(), key=lambda item: item[1])})\n",
    "            Prototypes.append(self.median(sortedProjections[prototype_index]))\n",
    "            prototype_index += 1\n",
    "        \n",
    "        Prototypes, new_numofClusters = self.OptimizeClusterSelection(Prototypes, new_numofClusters)\n",
    "\n",
    "        \n",
    "        return np.array(Prototypes), new_numofClusters\n",
    "\n",
    "\n",
    "    def ApproximatedProjectionDistancesofCluster(self, right_rep, left_rep, cluster_id, clusterSet, pairDictionary):\n",
    "\n",
    "        distances_vector = dict()\n",
    "\n",
    "        if len(clusterSet) > 2:\n",
    "            rep_distance = self.dissimilarityDistance(right_rep,left_rep)\n",
    "\n",
    "            for str_inCluster in range(0, len(clusterSet)):\n",
    "                if clusterSet[str_inCluster] != right_rep and clusterSet[str_inCluster] != left_rep:\n",
    "                    right_rep_distance = self.dissimilarityDistance(right_rep,clusterSet[str_inCluster])\n",
    "                    left_rep_distance  = self.dissimilarityDistance(left_rep,clusterSet[str_inCluster])\n",
    "\n",
    "                    if rep_distance == 0:\n",
    "                        distances_vector[clusterSet[str_inCluster]] = 0\n",
    "                    else:\n",
    "                        distances_vector[clusterSet[str_inCluster]] = (right_rep_distance**2-rep_distance**2-left_rep_distance**2 ) / (2*rep_distance)\n",
    "\n",
    "        else:\n",
    "            if left_rep != None and right_rep == None:\n",
    "                distances_vector[left_rep] = left_rep\n",
    "            elif right_rep != None and left_rep == None:\n",
    "                distances_vector[right_rep] = right_rep\n",
    "            elif left_rep != None and right_rep != None:\n",
    "                distances_vector[right_rep] = right_rep\n",
    "            elif left_rep == None and right_rep == None:\n",
    "                return None\n",
    "                \n",
    "        return distances_vector\n",
    "\n",
    "    def median(self, distances):\n",
    "        '''\n",
    "        Returns the median value of a vector\n",
    "        '''\n",
    "        keys = list(distances.keys())\n",
    "        if keys == 1:\n",
    "            return keys[0]\n",
    "\n",
    "        keys = list(distances.keys())\n",
    "        median_position = int(len(keys)/2)\n",
    "        median_value = keys[median_position]\n",
    "\n",
    "        return median_value\n",
    "\n",
    "    def OptimizeClusterSelection(self,Prototypes,numOfPrototypes):\n",
    "\n",
    "        notwantedPrototypes = []\n",
    "        for pr_1 in range(0,numOfPrototypes):\n",
    "            for pr_2 in range(pr_1+1,numOfPrototypes):\n",
    "                if self.dissimilarityDistance(Prototypes[pr_1],Prototypes[pr_2]) < self.prototypesFilterThr:\n",
    "                    notwantedPrototypes.append(Prototypes[pr_2])\n",
    "\n",
    "        newPrototypes = list((set(Prototypes)).difference(set(notwantedPrototypes)))\n",
    "        \n",
    "        if self.verboseLevel > 1:\n",
    "            print(\"Prototypes before:\")\n",
    "            print(Prototypes)\n",
    "            print(\"Not wanted:\")\n",
    "            print(set(notwantedPrototypes) )\n",
    "            print(\"Final:\")\n",
    "            print(newPrototypes)\n",
    "\n",
    "        return newPrototypes,len(newPrototypes)\n",
    "\n",
    "\n",
    "    #####################################################################\n",
    "    #       2. Embeddings based on the Vantage objects                  #\n",
    "    #####################################################################\n",
    "\n",
    "    '''\n",
    "    CreateVantageEmbeddings(S,VantageObjects): Main function for creating the string embeddings based on the Vantage Objects\n",
    "    '''\n",
    "    def CreateVantageEmbeddings(self, S, VantageObjects, pairDictionary):\n",
    "\n",
    "        # ------- Distance computing ------- #\n",
    "        vectors = []\n",
    "        for s in tqdm(range(0,S.size)):\n",
    "            string_embedding = []\n",
    "            for p in range(0,VantageObjects.size):\n",
    "                if VantageObjects[p] != None:\n",
    "                    string_embedding.append(self.DistanceMetric(s,p,S,VantageObjects, pairDictionary))\n",
    "\n",
    "            # --- Ranking representation ---- #\n",
    "            ranked_string_embedding = stats.rankdata(string_embedding, method='min')\n",
    "\n",
    "            # ------- Vectors dataset ------- #\n",
    "            vectors.append(ranked_string_embedding)\n",
    "\n",
    "        return np.array(vectors)\n",
    "\n",
    "\n",
    "    '''\n",
    "    DistanceMetric(s,p,S,Prototypes): Embedding method used for creating the space of objects\n",
    "    '''\n",
    "    def DistanceMetric(self, s, p, S, VantageObjects, pairDictionary):\n",
    "\n",
    "        if self.distanceMetricEmbedding == 'l_inf':\n",
    "            return self.l_inf(VantageObjects,S,s,p)\n",
    "        elif self.distanceMetricEmbedding == 'edit':\n",
    "            return self.dissimilarityDistance(S[s],VantageObjects[p])\n",
    "        elif self.distanceMetricEmbedding == 'jaccard':\n",
    "            return jaccard_distance(self.S_set[S[s]],self.S_set[VantageObjects[p]])\n",
    "        elif self.distanceMetricEmbedding == 'euclid_jaccard':\n",
    "            return self.hybrid_euclidJaccard(self.S_set[S[s]],self.S_set[VantageObjects[p]])\n",
    "        else:\n",
    "            warnings.warn(\"Available metrics: edit,jaccard,l_inf\")\n",
    "\n",
    "\n",
    "    def dropNone(array):\n",
    "        array = list(filter(None, list(array)))\n",
    "        return np.array(array)\n",
    "    \n",
    "    def l_inf(self,VantageObjects,S,s,p):\n",
    "        max_distance = None\n",
    "        for pp in range(0,VantageObjects.size):\n",
    "            if VantageObjects[pp] != None:\n",
    "                string_distance = self.dissimilarityDistance(S[s],VantageObjects[pp])    # distance String-i -> Vantage Object\n",
    "                VO_distance     = self.dissimilarityDistance(VantageObjects[p],VantageObjects[pp])    # distance Vantage Object-j -> Vantage Object-i\n",
    "\n",
    "                abs_diff = abs(string_distance-VO_distance)\n",
    "\n",
    "                # --- Max distance diff --- #\n",
    "                if max_distance == None:\n",
    "                    max_distance = abs_diff\n",
    "                elif abs_diff > max_distance:\n",
    "                    max_distance = abs_diff\n",
    "                    \n",
    "        return max_distance\n",
    "    \n",
    "    def hybrid_euclidJaccard(self,s,p): \n",
    "        return math.sqrt(jaccard_distance(s,p))\n",
    "    \n",
    "    #####################################################################\n",
    "    #                 3. Similarity checking                            #\n",
    "    #####################################################################\n",
    "\n",
    "    def SimilarityEvaluation(self, buckets,vectors,threshold,maxOnly=None,metric=None):\n",
    "\n",
    "        numOfVectors = vectors.shape[0]\n",
    "        vectorDim    = vectors.shape[1]\n",
    "        mapping_matrix = np.zeros([numOfVectors,numOfVectors],dtype=np.int8)\n",
    "        self.similarityProb_matrix = np.empty([numOfVectors,numOfVectors],dtype=np.float)* np.nan\n",
    "        mapping = {}\n",
    "        \n",
    "        self.numOfComparisons = 0\n",
    "        self.diffObjectsComparedSuccess = 0\n",
    "        self.sameObjectsCompared = 0\n",
    "        self.sameObjectsComparedSuccess = 0\n",
    "        \n",
    "        # Loop for every bucket\n",
    "        for bucketid in tqdm(buckets.keys()):\n",
    "            bucket_vectors = buckets[bucketid]\n",
    "            numOfVectors = len(bucket_vectors)\n",
    "            \n",
    "            if self.verboseLevel > 0:\n",
    "                print(bucket_vectors)\n",
    "            \n",
    "            # For every vector inside the bucket\n",
    "            for v_index in range(0,numOfVectors,1):\n",
    "                v_vector_id = bucket_vectors[v_index]\n",
    "                # Loop to all the other\n",
    "                for i_index in range(v_index+1,numOfVectors,1):\n",
    "                    i_vector_id = bucket_vectors[i_index]\n",
    "                    if vectorDim == 1:\n",
    "                        warnings.warn(\"Vector dim equal to 1- Setting metric to kendalltau\")\n",
    "                        metric = 'kendal'\n",
    "                    \n",
    "                    self.numOfComparisons+=1\n",
    "                    \n",
    "                    if metric == None or metric == 'kendal':  # Simple Kendal tau metric\n",
    "                        similarity_prob, p_value = kendalltau(vectors[v_vector_id], vectors[i_vector_id])\n",
    "                    elif metric == 'customKendal':  # Custom Kendal tau\n",
    "                        numOf_discordant_pairs = _kendall_dis(vectors[v_vector_id].astype('intp'), vectors[i_vector_id].astype('intp'))\n",
    "                        similarity_prob = (2*numOf_discordant_pairs) / (vectorDim*(vectorDim-1))\n",
    "                    elif metric == 'jaccard':\n",
    "                        similarity_prob = jaccard_score(vectors[v_vector_id], vectors[i_vector_id], average='micro')\n",
    "                    elif metric == 'cosine':\n",
    "                        similarity_prob = cosine_similarity(np.array(vectors[v_vector_id]).reshape(1, -1), np.array(vectors[i_vector_id]).reshape(1, -1))\n",
    "                    elif metric == 'pearson':\n",
    "                        similarity_prob, _ = pearsonr(vectors[v_vector_id], vectors[i_vector_id])\n",
    "                    elif metric == 'spearman':\n",
    "                        similarity_prob, _ = spearmanr(vectors[v_vector_id], vectors[i_vector_id])\n",
    "                    elif metric == 'spearmanf':\n",
    "                        similarity_prob = 1-spearman_footrule_distance(vectors[v_vector_id], vectors[i_vector_id])\n",
    "                    elif metric == 'hamming':\n",
    "                        similarity_prob, _ = hamming(vectors[v_vector_id].astype('intp'), vectors[i_vector_id].astype('intp'))\n",
    "                    elif metric == 'kruskal':\n",
    "                        if np.array_equal(vectors[v_vector_id],vectors[i_vector_id]):\n",
    "                            similarity_prob=1.0\n",
    "                        else:\n",
    "                            _,similarity_prob = kruskal(vectors[v_vector_id], vectors[i_vector_id])\n",
    "                    elif metric == 'ndcg_score':\n",
    "                        similarity_prob, _ = ndcg_score(vectors[v_vector_id], vectors[i_vector_id])\n",
    "                    elif metric == 'rbo':\n",
    "                        similarity_prob = rbo(vectors[v_vector_id], vectors[i_vector_id], self.rbo_p)\n",
    "                    elif metric == 'wta':\n",
    "                        similarity_prob = WTA_similarity(vectors[v_vector_id], vectors[i_vector_id])\n",
    "                    elif metric == 'mannwhitneyu':\n",
    "                        if np.array_equal(vectors[v_vector_id],vectors[i_vector_id]):\n",
    "                            similarity_prob=1.0\n",
    "                        else:\n",
    "                            _,similarity_prob = mannwhitneyu(vectors[v_vector_id], vectors[i_vector_id])\n",
    "                    else:\n",
    "                        warnings.warn(\"SimilarityEvaluation: Available similarity metrics: kendal,customKendal,jaccard,ndcg_score,cosine,spearman,pearson\")\n",
    "\n",
    "\n",
    "                    self.similarityProb_matrix[v_vector_id][i_vector_id] = similarity_prob\n",
    "                    self.similarityProb_matrix[i_vector_id][v_vector_id] = similarity_prob\n",
    "                    \n",
    "                    if true_matrix[v_vector_id][i_vector_id] or true_matrix[i_vector_id][v_vector_id]:\n",
    "                        self.sameObjectsCompared += 1\n",
    "\n",
    "                    if similarity_prob > threshold:\n",
    "                        if v_vector_id not in mapping.keys():\n",
    "                            mapping[v_vector_id] = []\n",
    "                        mapping[v_vector_id].append(i_vector_id)  # insert into mapping\n",
    "                        mapping_matrix[v_vector_id][i_vector_id] = 1  # inform prediction matrix\n",
    "                        mapping_matrix[i_vector_id][v_vector_id] = 1  # inform prediction matrix\n",
    "                        if true_matrix[v_vector_id][i_vector_id] or true_matrix[i_vector_id][v_vector_id]:\n",
    "                            self.sameObjectsComparedSuccess += 1\n",
    "                    elif similarity_prob <= threshold and true_matrix[v_vector_id][i_vector_id] == 0 and true_matrix[i_vector_id][v_vector_id] == 0:\n",
    "                        self.diffObjectsComparedSuccess += 1\n",
    "\n",
    "\n",
    "        return mapping, np.triu(mapping_matrix)\n",
    "\n",
    "    #####################################################################\n",
    "    #                        4. WTA Hashing                             #\n",
    "    #####################################################################\n",
    "\n",
    "    def WTA(self,vectors,K, number_of_permutations):\n",
    "        '''\n",
    "          Winner Take All hash - Yagnik\n",
    "          .............................\n",
    "    \n",
    "          K: window size\n",
    "        '''\n",
    "        newVectors = []\n",
    "        buckets = dict()\n",
    "\n",
    "        numOfVectors = vectors.shape[0]\n",
    "        vectorDim    = vectors.shape[1]\n",
    "\n",
    "        if vectorDim < K:\n",
    "            K = vectorDim\n",
    "            warnings.warn(\"Window size greater than vector dimension\")\n",
    "\n",
    "        C = np.zeros([numOfVectors,number_of_permutations], dtype=int)\n",
    "\n",
    "        permutation_dimension = vectorDim\n",
    "        for permutation_index in tqdm(range(0,number_of_permutations,1)):\n",
    "            theta = np.random.permutation(permutation_dimension)\n",
    "            i=0;j=0;\n",
    "            for v_index in range(0,numOfVectors,1):\n",
    "                if permutation_index == 0:\n",
    "                    X_new = self.permuted(vectors[v_index],theta)\n",
    "                    newVectors.append(X_new)\n",
    "                else:\n",
    "                    X_new = self.permuted(vectors[v_index],theta)\n",
    "                    newVectors[v_index] = X_new\n",
    "\n",
    "                C[i][permutation_index] = max(range(len(X_new[:K])), key=X_new[:K].__getitem__)\n",
    "                i+=1\n",
    "            \n",
    "\n",
    "        for c,i in zip(C,range(0,numOfVectors,1)):\n",
    "            buckets = self.bucketInsert(buckets,str(c),i)\n",
    "\n",
    "        return C,buckets,np.array(newVectors,dtype=np.intp)\n",
    "\n",
    "\n",
    "    def permuted(self,vector,permutation):\n",
    "        permuted_vector = [vector[x] for x in permutation]\n",
    "\n",
    "        return permuted_vector\n",
    "\n",
    "\n",
    "    def bucketInsert(self,buckets,bucket_id,item):\n",
    "        if bucket_id not in buckets.keys():\n",
    "            buckets[bucket_id] = []\n",
    "        buckets[bucket_id].append(item)\n",
    "\n",
    "        return buckets\n",
    "\n",
    "    \n",
    "#####################################################################\n",
    "#                          Evaluation                               # \n",
    "#####################################################################\n",
    "# warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "def report(model):\n",
    "    \n",
    "    print(\"\\n--- DETAILED REPORT ---\\n\\n\")\n",
    "    print(\"\\n> 1. Prototype selection\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"\\n> 2. Embedding phase\\n\")\n",
    "    \n",
    "    print(\"\\n> 3. WTA hashing\\n\")\n",
    "    print(\"Number of buckets created \", len(model.buckets.keys()))\n",
    "    for key in model.buckets.keys():\n",
    "        print(key,\" -> \", len(model.buckets[key]))\n",
    "        \n",
    "    print(\"\\n> 4. Similarity checking\\n\")\n",
    "    print(\"Total comparisons: \", model.numOfComparisons)\n",
    "    print(\" -> between same objects: \", model.sameObjectsCompared )\n",
    "    print(\" -> between same objects with success: \", model.sameObjectsComparedSuccess)\n",
    "    print(\" -> between different objects with success: \", model.diffObjectsComparedSuccess )\n",
    "    \n",
    "\n",
    "def customClassificationReport(predicted_matrix, true_matrix):\n",
    "    \n",
    "    size = len(predicted_matrix)\n",
    "    true_positives = 0; false_positives = 0; true_negatives = 0; false_negatives = 0;\n",
    "    i=0\n",
    "    while i < size:\n",
    "        j = i\n",
    "        while j < size:\n",
    "            if predicted_matrix[i][j] == true_matrix[i][j] == 1:\n",
    "                true_positives += 1\n",
    "            elif predicted_matrix[i][j] == true_matrix[i][j] == 0:\n",
    "                true_negatives += 1\n",
    "            elif predicted_matrix[i][j] == 0 and true_matrix[i][j] == 1:\n",
    "                false_negatives += 1\n",
    "            elif predicted_matrix[i][j] == 1 and true_matrix[i][j] == 0:\n",
    "                false_positives += 1            \n",
    "            j += 1\n",
    "        i += 1\n",
    "        \n",
    "    accuracy = ((true_positives + true_negatives) / (true_positives + false_positives + true_negatives + false_negatives))*100\n",
    "    precision = (true_positives / (true_positives + false_positives))*100\n",
    "    recall = (true_positives / (true_positives + false_negatives))*100\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    print(\"Accuracy:  %.2f %%\" % (accuracy))\n",
    "    print(\"F1-Score:  %.2f %%\" % (f1))\n",
    "    print(\"Recall:    %.2f %%\" % (recall))\n",
    "    print(\"Precision: %.2f %%\" % (precision))\n",
    "    \n",
    "    print(\"True positives:  \", true_positives)\n",
    "    print(\"True negatives:  \", true_negatives)\n",
    "    print(\"False positives: \", false_positives)\n",
    "    print(\"False negatives: \", false_negatives)\n",
    "\n",
    "def evaluate(predicted_matrix, true_matrix, with_classification_report=False):\n",
    "\n",
    "    print(\"#####################################################################\\n#                          Evaluation                               #\\n#####################################################################\\n\")\n",
    "    transformToVector = np.triu_indices(len(model.mapping_matrix))    \n",
    "    true_matrix = true_matrix[transformToVector]\n",
    "    predicted_matrix = predicted_matrix[transformToVector]\n",
    "    \n",
    "    acc = 100*accuracy_score(true_matrix, predicted_matrix)\n",
    "    f1 =  100*f1_score(true_matrix, predicted_matrix)\n",
    "    recall = 100*recall_score(true_matrix, predicted_matrix)\n",
    "    precision = 100*precision_score(true_matrix, predicted_matrix)\n",
    "\n",
    "    print(\"Accuracy:  %3.2f %%\" % (acc))\n",
    "    print(\"F1-Score:  %3.2f %%\" % (f1))\n",
    "    print(\"Recall:    %3.2f %%\" % (recall))\n",
    "    print(\"Precision: %3.2f %%\" % (precision))\n",
    "\n",
    "    if with_classification_report:\n",
    "        print(\"\\nClassification report:\\n\")\n",
    "        print(classification_report(true_matrix, predicted_matrix))\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    cm = sklearn.metrics.confusion_matrix(true_matrix,predicted_matrix,labels=[0,1])\n",
    "    create_ConfusionMatrix(cm,'Confusion matrix')\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    \n",
    "    return acc,f1,precision,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# __Evaluation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data from Drive in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Opening data file\n",
    "# import io\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive',force_remount=True)\n",
    "\n",
    "# fpcora = r\"/content/drive/My Drive/ERinDS/CORA.xml\"\n",
    "# fpcora_gold = r\"/content/drive/My Drive/ERinDS/cora_gold.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from disk for Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JedAI Dirty datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Id</th>\n",
       "      <th>address</th>\n",
       "      <th>author</th>\n",
       "      <th>editor</th>\n",
       "      <th>institution</th>\n",
       "      <th>month</th>\n",
       "      <th>note</th>\n",
       "      <th>pages</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>los alamitos, ca:</td>\n",
       "      <td>p. auer, n. cesa-bianchi, y. freund, and r. e....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pp. 322-331.</td>\n",
       "      <td>ieee computer society press,</td>\n",
       "      <td>'gambling in a rigged casino: the adversarial ...</td>\n",
       "      <td>in proc. 36th annual symposium on foundations ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a. blum, m. furst, m. j. kearns, and richard j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pages 24.1-24.10,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cryptographic primitives based on hard learnin...</td>\n",
       "      <td>in pre-proceedings of crypto '93,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avrim blum, merrick furst, michael kearns, and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pages 24.1-24.10,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cryptographic primitives based on hard learnin...</td>\n",
       "      <td>in pre-proceedings of crypto '93,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avrim blum, merrick furst, michael kearns, and...</td>\n",
       "      <td>in douglas r. stinson, editor,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lecture notes in computer science no. 773.</td>\n",
       "      <td>pages 278-291.</td>\n",
       "      <td>springer,</td>\n",
       "      <td>cryptographic primitives based on hard learnin...</td>\n",
       "      <td>proc. crypto 93,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a. blum, m. furst, m. kearns, r. lipton.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cryptographic primitives based on hard learnin...</td>\n",
       "      <td>crypto,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>robert e. schapire and yoram singer.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>improved boosting algorithms using confidence-...</td>\n",
       "      <td>in proceedings of the eleventh annual conferen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>schapire, r. e., freund, y., bartlett, p., &amp; l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>annals of statistics (to appear).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boosting the margin: a new explanation for the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1998).</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>robert e. schapire and yoram singer. boostexter:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a system for multiclass multi-label text categ...</td>\n",
       "      <td>unpublished manuscript,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>robert e. schapire yoram singer.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submitted for publication. 17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>improved boosting algorithms using confidence-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>robert e. schapire yoram singer.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submitted for publication.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>improved boosting algorithms using confidence-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1295 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Entity Id            address  \\\n",
       "0             0  los alamitos, ca:   \n",
       "1             1                NaN   \n",
       "2             2                NaN   \n",
       "3             3                NaN   \n",
       "4             4                NaN   \n",
       "...         ...                ...   \n",
       "1290       1290                NaN   \n",
       "1291       1291                NaN   \n",
       "1292       1292                NaN   \n",
       "1293       1293                NaN   \n",
       "1294       1294                NaN   \n",
       "\n",
       "                                                 author  \\\n",
       "0     p. auer, n. cesa-bianchi, y. freund, and r. e....   \n",
       "1     a. blum, m. furst, m. j. kearns, and richard j...   \n",
       "2     avrim blum, merrick furst, michael kearns, and...   \n",
       "3     avrim blum, merrick furst, michael kearns, and...   \n",
       "4              a. blum, m. furst, m. kearns, r. lipton.   \n",
       "...                                                 ...   \n",
       "1290               robert e. schapire and yoram singer.   \n",
       "1291  schapire, r. e., freund, y., bartlett, p., & l...   \n",
       "1292   robert e. schapire and yoram singer. boostexter:   \n",
       "1293                   robert e. schapire yoram singer.   \n",
       "1294                   robert e. schapire yoram singer.   \n",
       "\n",
       "                              editor institution month  \\\n",
       "0                                NaN         NaN   NaN   \n",
       "1                                NaN         NaN   NaN   \n",
       "2                                NaN         NaN   NaN   \n",
       "3     in douglas r. stinson, editor,         NaN   NaN   \n",
       "4                                NaN         NaN   NaN   \n",
       "...                              ...         ...   ...   \n",
       "1290                             NaN         NaN   NaN   \n",
       "1291                             NaN         NaN   NaN   \n",
       "1292                             NaN         NaN   NaN   \n",
       "1293                             NaN         NaN   NaN   \n",
       "1294                             NaN         NaN   NaN   \n",
       "\n",
       "                                            note              pages  \\\n",
       "0                                            NaN       pp. 322-331.   \n",
       "1                                            NaN  pages 24.1-24.10,   \n",
       "2                                            NaN  pages 24.1-24.10,   \n",
       "3     lecture notes in computer science no. 773.     pages 278-291.   \n",
       "4                                            NaN                NaN   \n",
       "...                                          ...                ...   \n",
       "1290                                         NaN                NaN   \n",
       "1291           annals of statistics (to appear).                NaN   \n",
       "1292                                         NaN                NaN   \n",
       "1293               submitted for publication. 17                NaN   \n",
       "1294                  submitted for publication.                NaN   \n",
       "\n",
       "                         publisher  \\\n",
       "0     ieee computer society press,   \n",
       "1                              NaN   \n",
       "2                              NaN   \n",
       "3                        springer,   \n",
       "4                              NaN   \n",
       "...                            ...   \n",
       "1290                           NaN   \n",
       "1291                           NaN   \n",
       "1292                           NaN   \n",
       "1293                           NaN   \n",
       "1294                           NaN   \n",
       "\n",
       "                                                  title  \\\n",
       "0     'gambling in a rigged casino: the adversarial ...   \n",
       "1     cryptographic primitives based on hard learnin...   \n",
       "2     cryptographic primitives based on hard learnin...   \n",
       "3     cryptographic primitives based on hard learnin...   \n",
       "4     cryptographic primitives based on hard learnin...   \n",
       "...                                                 ...   \n",
       "1290  improved boosting algorithms using confidence-...   \n",
       "1291  boosting the margin: a new explanation for the...   \n",
       "1292  a system for multiclass multi-label text categ...   \n",
       "1293  improved boosting algorithms using confidence-...   \n",
       "1294  improved boosting algorithms using confidence-...   \n",
       "\n",
       "                                                  venue volume     year  \\\n",
       "0     in proc. 36th annual symposium on foundations ...    NaN    1995,   \n",
       "1                     in pre-proceedings of crypto '93,    NaN    1993.   \n",
       "2                     in pre-proceedings of crypto '93,    NaN    1993.   \n",
       "3                                      proc. crypto 93,    NaN    1994.   \n",
       "4                                               crypto,    NaN    1993.   \n",
       "...                                                 ...    ...      ...   \n",
       "1290  in proceedings of the eleventh annual conferen...    NaN    1998.   \n",
       "1291                                                NaN    NaN  (1998).   \n",
       "1292                            unpublished manuscript,    NaN    1998.   \n",
       "1293                                                NaN    NaN      NaN   \n",
       "1294                                                NaN    NaN      NaN   \n",
       "\n",
       "      Unnamed: 13  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "...           ...  \n",
       "1290          NaN  \n",
       "1291          NaN  \n",
       "1292          NaN  \n",
       "1293          NaN  \n",
       "1294          NaN  \n",
       "\n",
       "[1295 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORA_groundTruth = os.path.abspath(\"data/coraIdDuplicates.csv\")\n",
    "CORA = os.path.abspath(\"data/coraProfiles.csv\")\n",
    "CORA_groundTruth = pd.read_csv(CORA_groundTruth,sep='|',header=None,names=['id1','id2'])\n",
    "CORA_groundTruth=CORA_groundTruth.sort_values(by=['id1','id2'],ignore_index=True)\n",
    "CORA = pd.read_csv(CORA,sep='|')\n",
    "CORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id1  id2\n",
       "0    1    2\n",
       "1    1    3\n",
       "2    1    4\n",
       "3    2    3\n",
       "4    2    4\n",
       "5    3    4\n",
       "6    5    6\n",
       "7    5    7\n",
       "8    5    8\n",
       "9    5    9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORA_groundTruth.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CENSUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Id</th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "      <th>attr4</th>\n",
       "      <th>attr5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4848</td>\n",
       "      <td>BASSWOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4848</td>\n",
       "      <td>BASSWOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4848</td>\n",
       "      <td>BASSWOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4848</td>\n",
       "      <td>BASSWOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AQUENDO</td>\n",
       "      <td>CLARA</td>\n",
       "      <td>J</td>\n",
       "      <td>666</td>\n",
       "      <td>STARKEY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>836</td>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>SHERRY</td>\n",
       "      <td>V</td>\n",
       "      <td>510</td>\n",
       "      <td>WOODHAVEN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>837</td>\n",
       "      <td>WRIGHT</td>\n",
       "      <td>BRYAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "      <td>WOODHAVEN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>838</td>\n",
       "      <td>WRIGHT</td>\n",
       "      <td>MAXINE</td>\n",
       "      <td>H</td>\n",
       "      <td>307</td>\n",
       "      <td>WOODHAVEN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>839</td>\n",
       "      <td>YATES</td>\n",
       "      <td>CHANSE</td>\n",
       "      <td>E</td>\n",
       "      <td>403</td>\n",
       "      <td>WOODHAVEN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>840</td>\n",
       "      <td>YATES</td>\n",
       "      <td>ALFREDICA</td>\n",
       "      <td>S</td>\n",
       "      <td>403</td>\n",
       "      <td>WOODHAVEN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>841 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Entity Id     attr1      attr2 attr3 attr4      attr5  Unnamed: 6\n",
       "0            0  ANDERSON        NaN   NaN  4848   BASSWOOD         NaN\n",
       "1            1  ANDERSON        NaN   NaN  4848   BASSWOOD         NaN\n",
       "2            2  ANDERSON        NaN   NaN  4848   BASSWOOD         NaN\n",
       "3            3  ANDERSON        NaN   NaN  4848   BASSWOOD         NaN\n",
       "4            4   AQUENDO      CLARA     J   666    STARKEY         NaN\n",
       "..         ...       ...        ...   ...   ...        ...         ...\n",
       "836        836   WILLIAM     SHERRY     V   510  WOODHAVEN         NaN\n",
       "837        837    WRIGHT      BRYAN   NaN   307  WOODHAVEN         NaN\n",
       "838        838    WRIGHT     MAXINE     H   307  WOODHAVEN         NaN\n",
       "839        839     YATES     CHANSE     E   403  WOODHAVEN         NaN\n",
       "840        840     YATES  ALFREDICA     S   403  WOODHAVEN         NaN\n",
       "\n",
       "[841 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CENSUS_groundTruth = os.path.abspath(\"data/censusIdDuplicates.csv\")\n",
    "CENSUS = os.path.abspath(\"data/censusProfiles.csv\")\n",
    "CENSUS_groundTruth = pd.read_csv(CENSUS_groundTruth,sep='|',header=None,names=['id1','id2'])\n",
    "CENSUS = pd.read_csv(CENSUS,sep='|')\n",
    "CENSUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>427</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>299</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>433</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>366</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>651</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>226</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>305</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id1  id2\n",
       "0     85  530\n",
       "1    427  816\n",
       "2    360  748\n",
       "3     18  462\n",
       "4    299  692\n",
       "..   ...  ...\n",
       "339  433  827\n",
       "340  366  755\n",
       "341  651  652\n",
       "342  226  602\n",
       "343  305  701\n",
       "\n",
       "[344 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CENSUS_groundTruth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CDDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Id|artist</th>\n",
       "      <th>category</th>\n",
       "      <th>cdextra</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>track01</th>\n",
       "      <th>track02</th>\n",
       "      <th>track03</th>\n",
       "      <th>track04</th>\n",
       "      <th>track05</th>\n",
       "      <th>...</th>\n",
       "      <th>track92</th>\n",
       "      <th>track93</th>\n",
       "      <th>track94</th>\n",
       "      <th>track95</th>\n",
       "      <th>track96</th>\n",
       "      <th>track97</th>\n",
       "      <th>track98</th>\n",
       "      <th>track99</th>\n",
       "      <th>year</th>\n",
       "      <th>Unnamed: 105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pink floyd</td>\n",
       "      <td>data</td>\n",
       "      <td>ID3G: 254</td>\n",
       "      <td>Data</td>\n",
       "      <td>the wall disc 1</td>\n",
       "      <td>in the flesh</td>\n",
       "      <td>the thin ice</td>\n",
       "      <td>another brick in the wall part 1</td>\n",
       "      <td>the happiest days of our lives</td>\n",
       "      <td>another brick in the wall part 2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlos Santana</td>\n",
       "      <td>data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carlos</td>\n",
       "      <td>(Da Le) Yaleo</td>\n",
       "      <td>Love Of My Life</td>\n",
       "      <td>Put You Love Lights On</td>\n",
       "      <td>Smooth</td>\n",
       "      <td>Do You Like The Way?</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frans Bauer</td>\n",
       "      <td>data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>'n ons geluk</td>\n",
       "      <td>'n ONS geluk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2Pac</td>\n",
       "      <td>data</td>\n",
       "      <td>YEAR: 1998 ID3G: 15</td>\n",
       "      <td>Rap</td>\n",
       "      <td>Greatest Hits (CD1)</td>\n",
       "      <td>Keep Ya Head Up</td>\n",
       "      <td>2 Of Amerikaz Most Wanted (Ft. Snoop Dogg)</td>\n",
       "      <td>Temptations</td>\n",
       "      <td>God Bless The Dead</td>\n",
       "      <td>Hail Mary</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ì¤ï¿½ï¿½</td>\n",
       "      <td>data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ì¤ï¿½ï¿½</td>\n",
       "      <td>ï¿½È¥ï¿½Ã¥ï¿½ 1</td>\n",
       "      <td>ï¿½È¥ï¿½Ã¥ï¿½ 2</td>\n",
       "      <td>ï¿½È¥ï¿½Ã¥ï¿½ 3</td>\n",
       "      <td>ï¿½È¥ï¿½Ã¥ï¿½ 4</td>\n",
       "      <td>ï¿½È¥ï¿½Ã¥ï¿½ 5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>Various</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Warriors of Virtue</td>\n",
       "      <td>You Can Fly</td>\n",
       "      <td>A Beautiful Morning</td>\n",
       "      <td>Forces of Nature</td>\n",
       "      <td>Inside of You</td>\n",
       "      <td>Tennessee Plates</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>James Patterson</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Soundtrack</td>\n",
       "      <td>Pop Goes the Weasel - CD 4</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.05</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9760</th>\n",
       "      <td>Colin Baker &amp; Nicholas Courtney</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>Published by Big Finish Productions.\\nhttp://w...</td>\n",
       "      <td>Soundtrack</td>\n",
       "      <td>The Spectre of Lanyon Moor</td>\n",
       "      <td>Episode 0</td>\n",
       "      <td>Episode 1 Part 1</td>\n",
       "      <td>Episode 1 Part 2</td>\n",
       "      <td>Episode 1 Part 3</td>\n",
       "      <td>Episode 1 Part 4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>Studio Cutz</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>ID3G: 24</td>\n",
       "      <td>Soundtrack</td>\n",
       "      <td>Volume 25</td>\n",
       "      <td>All Access 3:12</td>\n",
       "      <td>All Access 3:12 alt</td>\n",
       "      <td>All Access :60</td>\n",
       "      <td>All Access :30</td>\n",
       "      <td>All Access :11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9762</th>\n",
       "      <td>Audio Adventures In Time &amp; Space/2)</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>Published by BBV.\\nhttp://www.bbvonline.co.uk/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prosperity Island (Disk 2/2)</td>\n",
       "      <td>Chapter 15</td>\n",
       "      <td>Chapter 16</td>\n",
       "      <td>Chapter 17</td>\n",
       "      <td>Chapter 18</td>\n",
       "      <td>Chapter 19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9763 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Entity Id|artist    category  \\\n",
       "0                              pink floyd        data   \n",
       "1                          Carlos Santana        data   \n",
       "2                             Frans Bauer        data   \n",
       "3                                    2Pac        data   \n",
       "4                                Ì¤ï¿½ï¿½        data   \n",
       "...                                   ...         ...   \n",
       "9758                              Various  soundtrack   \n",
       "9759                      James Patterson  soundtrack   \n",
       "9760      Colin Baker & Nicholas Courtney  soundtrack   \n",
       "9761                          Studio Cutz  soundtrack   \n",
       "9762  Audio Adventures In Time & Space/2)  soundtrack   \n",
       "\n",
       "                                                cdextra       genre  \\\n",
       "0                                             ID3G: 254        Data   \n",
       "1                                                   NaN         NaN   \n",
       "2                                                   NaN       Other   \n",
       "3                                   YEAR: 1998 ID3G: 15         Rap   \n",
       "4                                                   NaN         NaN   \n",
       "...                                                 ...         ...   \n",
       "9758                                                NaN         NaN   \n",
       "9759                                                NaN  Soundtrack   \n",
       "9760  Published by Big Finish Productions.\\nhttp://w...  Soundtrack   \n",
       "9761                                           ID3G: 24  Soundtrack   \n",
       "9762  Published by BBV.\\nhttp://www.bbvonline.co.uk/...         NaN   \n",
       "\n",
       "                             title          track01  \\\n",
       "0                  the wall disc 1     in the flesh   \n",
       "1                           Carlos    (Da Le) Yaleo   \n",
       "2                     'n ons geluk     'n ONS geluk   \n",
       "3              Greatest Hits (CD1)  Keep Ya Head Up   \n",
       "4                         Ì¤ï¿½ï¿½  ï¿½È¥ï¿½Ã¥ï¿½ 1   \n",
       "...                            ...              ...   \n",
       "9758            Warriors of Virtue      You Can Fly   \n",
       "9759    Pop Goes the Weasel - CD 4             4.01   \n",
       "9760    The Spectre of Lanyon Moor        Episode 0   \n",
       "9761                     Volume 25  All Access 3:12   \n",
       "9762  Prosperity Island (Disk 2/2)       Chapter 15   \n",
       "\n",
       "                                         track02  \\\n",
       "0                                   the thin ice   \n",
       "1                                Love Of My Life   \n",
       "2                                            NaN   \n",
       "3     2 Of Amerikaz Most Wanted (Ft. Snoop Dogg)   \n",
       "4                                ï¿½È¥ï¿½Ã¥ï¿½ 2   \n",
       "...                                          ...   \n",
       "9758                         A Beautiful Morning   \n",
       "9759                                        4.02   \n",
       "9760                            Episode 1 Part 1   \n",
       "9761                         All Access 3:12 alt   \n",
       "9762                                  Chapter 16   \n",
       "\n",
       "                               track03                         track04  \\\n",
       "0     another brick in the wall part 1  the happiest days of our lives   \n",
       "1               Put You Love Lights On                          Smooth   \n",
       "2                                  NaN                             NaN   \n",
       "3                          Temptations              God Bless The Dead   \n",
       "4                      ï¿½È¥ï¿½Ã¥ï¿½ 3                 ï¿½È¥ï¿½Ã¥ï¿½ 4   \n",
       "...                                ...                             ...   \n",
       "9758                  Forces of Nature                   Inside of You   \n",
       "9759                              4.03                            4.04   \n",
       "9760                  Episode 1 Part 2                Episode 1 Part 3   \n",
       "9761                    All Access :60                  All Access :30   \n",
       "9762                        Chapter 17                      Chapter 18   \n",
       "\n",
       "                               track05  ... track92 track93 track94 track95  \\\n",
       "0     another brick in the wall part 2  ...     NaN     NaN     NaN     NaN   \n",
       "1                 Do You Like The Way?  ...     NaN     NaN     NaN     NaN   \n",
       "2                                  NaN  ...     NaN     NaN     NaN     NaN   \n",
       "3                            Hail Mary  ...     NaN     NaN     NaN     NaN   \n",
       "4                      ï¿½È¥ï¿½Ã¥ï¿½ 5  ...     NaN     NaN     NaN     NaN   \n",
       "...                                ...  ...     ...     ...     ...     ...   \n",
       "9758                  Tennessee Plates  ...     NaN     NaN     NaN     NaN   \n",
       "9759                              4.05  ...     NaN     NaN     NaN     NaN   \n",
       "9760                  Episode 1 Part 4  ...     NaN     NaN     NaN     NaN   \n",
       "9761                    All Access :11  ...     NaN     NaN     NaN     NaN   \n",
       "9762                        Chapter 19  ...     NaN     NaN     NaN     NaN   \n",
       "\n",
       "     track96 track97 track98 track99  year Unnamed: 105  \n",
       "0        NaN     NaN     NaN     NaN   NaN          NaN  \n",
       "1        NaN     NaN     NaN     NaN   NaN          NaN  \n",
       "2        NaN     NaN     NaN     NaN  2004          NaN  \n",
       "3        NaN     NaN     NaN     NaN  1998          NaN  \n",
       "4        NaN     NaN     NaN     NaN   NaN          NaN  \n",
       "...      ...     ...     ...     ...   ...          ...  \n",
       "9758     NaN     NaN     NaN     NaN   NaN          NaN  \n",
       "9759     NaN     NaN     NaN     NaN  2000          NaN  \n",
       "9760     NaN     NaN     NaN     NaN  2000          NaN  \n",
       "9761     NaN     NaN     NaN     NaN   NaN          NaN  \n",
       "9762     NaN     NaN     NaN     NaN   NaN          NaN  \n",
       "\n",
       "[9763 rows x 106 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CDDB_groundTruth = os.path.abspath(\"data/cddbIdDuplicates.csv\")\n",
    "CDDB = os.path.abspath(\"data/cddbProfiles.csv\")\n",
    "CDDB_groundTruth = pd.read_csv(CDDB_groundTruth,sep='/00000',engine='python',header=None,names=['id1','id2'])\n",
    "CDDB = pd.read_csv(CDDB,sep='/00000',engine='python')\n",
    "CDDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>315</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>456</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>206</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>345</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>407</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>229</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>271</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id1  id2\n",
       "0    315  384\n",
       "1    456  457\n",
       "2     11   18\n",
       "3    133  134\n",
       "4     65  148\n",
       "..   ...  ...\n",
       "294  206  207\n",
       "295  345  446\n",
       "296  407  425\n",
       "297  229  350\n",
       "298  271  450\n",
       "\n",
       "[299 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CDDB_groundTruth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBLP - ACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACM = os.path.abspath(\"ACM.csv\")\n",
    "DBLP = os.path.abspath(\"DBLP2.csv\")\n",
    "ACM_DBLP_trueValues = os.path.abspath(\"DBLP-ACM_perfectMapping.csv\")\n",
    "ACM = pd.read_csv(ACM)\n",
    "DBLP = pd.read_csv(DBLP, encoding='latin-1')\n",
    "ACM_DBLP_trueValues = pd.read_csv(ACM_DBLP_trueValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CORA - 1st edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpcora = os.path.abspath(\"CORA.xml\")\n",
    "fpcora_gold = os.path.abspath(\"cora_gold.csv\")\n",
    "CORA1 = pdx.read_xml(fpcora,['CORA', 'NEWREFERENCE'],root_is_rows=False)\n",
    "CORA1['@id'] = pd.to_numeric(CORA1['@id']).subtract(1)\n",
    "CORA1_groundTruth = pd.read_csv(fpcora_gold,sep=';')\n",
    "CORA1_groundTruth['id1'] = pd.to_numeric(CORA1_groundTruth['id1']).subtract(1)\n",
    "CORA1_groundTruth['id2'] = pd.to_numeric(CORA1_groundTruth['id2']).subtract(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Maximum mean discrepancy (MMD)__, which measures the discrepancy between two distributions. The selection of prototypes creates a density distribution of prototypes. We want to evaluate whether the prototypes distribution differs from the data distribution. We estimate both with kernel density functions. The maximum mean discrepancy measures the difference between two distributions, which is the supremum over a function space of differences between the expectations according to the two distributions. All clear? Personally, I understand these concepts much better when I see how something is calculated with data. The following formula shows how to calculate the squared MMD measure (MMD2):\n",
    "    $$\n",
    "    MMD^2=\\frac{1}{m^2}\\sum_{i,j=1}^m{}k(z_i,z_j)-\\frac{2}{mn}\\sum_{i,j=1}^{m,n}k(z_i,x_j)+\\frac{1}{n^2}\\sum_{i,j=1}^n{}k(x_i,x_j)\n",
    "    $$\n",
    "    \n",
    "- __k__ is a kernel function that measures the similarity of two points\n",
    "- __m__ is the number of prototypes \n",
    "- __n__ is the number of data points x in our original dataset. \n",
    "- The prototypes z are a selection of data points x. \n",
    "\n",
    "    \n",
    "Each point is multidimensional, that is it can have multiple features. The goal of MMD-critic is to minimize MMD2. The closer MMD2 is to zero, the better the distribution of the prototypes fits the data. The key to bringing MMD2 down to zero is the term in the middle, which calculates the average proximity between the prototypes and all other data points (multiplied by 2). If this term adds up to the first term (the average proximity of the prototypes to each other) plus the last term (the average proximity of the data points to each other), then the prototypes explain the data perfectly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMMD2(model):    \n",
    "    mmdOnPrototypes = MMD2(model.dissimilarityDistance, model.S_index, model.prototypeArray)\n",
    "    print(\"MMD2: \",mmdOnPrototypes)        \n",
    "        \n",
    "        \n",
    "def MMD2(k, x, z):\n",
    "    \n",
    "    if type(x) is np.ndarray and type(z) is np.ndarray:\n",
    "        m = z.size\n",
    "        n = x.size\n",
    "    else:\n",
    "        m = len(z)\n",
    "        n = len(x)\n",
    "        \n",
    "    firstSum = 0.0\n",
    "    for i in range(0,m,1):\n",
    "        for j in range(0,m,1):\n",
    "            firstSum += k(z[i],z[j])\n",
    "    \n",
    "    secondSum = 0.0\n",
    "    for i in range(0,m,1):\n",
    "        for j in range(0,n,1):\n",
    "            secondSum += k(z[i],x[j])\n",
    "        \n",
    "    thirdSum = 0.0\n",
    "    for i in range(0,n,1):\n",
    "        for j in range(0,n,1):\n",
    "            thirdSum += k(x[i],x[j])\n",
    "    \n",
    "    mmd2 = (1/pow(m,2))*firstSum - (2/(m*n))*secondSum + (1/pow(n,2))*thirdSum\n",
    "    \n",
    "    \n",
    "    return mmd2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def myHeatmap(data,metric,distance):\n",
    "    if metric == 'edit':    \n",
    "        matrix  = np.zeros((len(data),len(data)), dtype=np.int)\n",
    "    else:\n",
    "        matrix = np.zeros((len(data),len(data)), dtype=np.float)\n",
    "    \n",
    "    for i in range(0,len(data),1):\n",
    "        for j in range(0,len(data),1):\n",
    "            if i != j:            \n",
    "                matrix[i][j]  = distance(data[i],data[j])\n",
    "\n",
    "                \n",
    "    fif,ax = plt.subplots(1,figsize=(10,10))\n",
    "    corr = np.corrcoef(matrix)\n",
    "    \n",
    "    mask = np.zeros_like(corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    ax = sns.heatmap(matrix, linewidth=0.5,annot=False,cmap=\"Blues_r\",mask=mask,fmt='.3g',ax=ax)\n",
    "    plt.show()\n",
    "    return matrix.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Jaccard VS Edit distance variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "import sklearn\n",
    "\n",
    "# Function that creates a confusion matrix\n",
    "def create_ConfusionMatrix(confusionMatrix,title):\n",
    "    plt.figure(figsize = (8,5))\n",
    "    classes = ['Different','Same']\n",
    "    cmap = plt.cm.Blues\n",
    "    plt.grid(False)\n",
    "    plt.imshow(confusionMatrix, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = confusionMatrix.max() / 2.\n",
    "    for i, j in itertools.product(range(confusionMatrix.shape[0]), range(confusionMatrix.shape[1])):\n",
    "        plt.text(j, i, confusionMatrix[i, j],horizontalalignment=\"center\",color=\"white\" if confusionMatrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.ylim([1.5, -.5])\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA for the embeddings evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "def PCA_SpaceVisualization(X,Prototypes,title='PCA visualization',withText=False,decompositionMenthod='PCA'):\n",
    "    '''\n",
    "    PCA to given array X and creating a plot\n",
    "    Returns PCA components array after fit_transform\n",
    "    '''\n",
    "    \n",
    "    # PCA code\n",
    "        # PCA code\n",
    "    if decompositionMenthod == 'PCA':\n",
    "        pca = PCA(n_components=2)\n",
    "    else:\n",
    "        pca = MDS(n_components=2)\n",
    "    pca.fit(X)\n",
    "    pcaComponents = pca.fit_transform(X) # pcaComponents is the data that I'll use from PCA\n",
    "    \n",
    "#     print(\"Explained varianse of PCA:\", pca.explained_variance_ratio_)\n",
    "    \n",
    "    # Seperating components\n",
    "    first_component = [x[0] for x in pcaComponents]\n",
    "    second_component = [x[1] for x in pcaComponents]\n",
    "    \n",
    "    # Plotting code\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "#     ax.scatter(first_component, second_component,alpha=0) \n",
    "    fig.suptitle(title,fontsize=15,fontweight=\"bold\")\n",
    "    \n",
    "    for x0, y0, i in zip(first_component, second_component,range(0,len(first_component),1)):\n",
    "        if(withText):\n",
    "            if i in Prototypes:\n",
    "                plt.text(x0,y0,i, ha=\"center\", va=\"center\",fontsize=16,color='r',fontweight=\"bold\")\n",
    "            else:\n",
    "                plt.text(x0,y0,i, ha=\"center\", va=\"center\",fontsize=8,color='b')\n",
    "        else:\n",
    "            if i in Prototypes:\n",
    "                plt.scatter(x0,y0,color='r',s=250,marker='*',alpha=1.0)\n",
    "            else:\n",
    "                plt.scatter(x0,y0,color='b',s=80,marker='.',alpha=1.0)\n",
    "    plt.show()\n",
    "    return pcaComponents\n",
    "\n",
    "def PCA_SpaceVisualization_3D(X,Prototypes,title='PCA visualization',withText=False,decompositionMenthod='PCA'):\n",
    "    \n",
    "    # PCA code\n",
    "    if decompositionMenthod == 'PCA':\n",
    "        pca = PCA(n_components=3)\n",
    "    else:\n",
    "        pca = MDS(n_components=3)\n",
    "    pca.fit(X)\n",
    "    pcaComponents = pca.fit_transform(X) # pcaComponents is the data that I'll use from PCA\n",
    "    \n",
    "    # Seperating components\n",
    "    first_component = [x[0] for x in pcaComponents]\n",
    "    second_component = [x[1] for x in pcaComponents]\n",
    "    third_component = [x[2] for x in pcaComponents]\n",
    "\n",
    "    # Plotting code\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    if decompositionMenthod == 'PCA':\n",
    "        print(\"Explained varianse of PCA:\", pca.explained_variance_ratio_)\n",
    "\n",
    "    \n",
    "    for x0, y0, z0, i in zip(first_component, second_component, third_component, range(0,len(first_component),1)):\n",
    "        if(withText):\n",
    "            if i in Prototypes:\n",
    "                plt.text(x0, y0, z0, i, ha=\"center\", va=\"center\", fontsize=16, color='r', fontweight=\"bold\")\n",
    "            else:\n",
    "                plt.text(x0, y0, z0, i, ha=\"center\", va=\"center\", fontsize=8, color='b')\n",
    "        else:\n",
    "            if i in Prototypes:\n",
    "                ax.scatter(x0, y0, z0, color='r', s=250, marker='*', alpha=1.0)\n",
    "            else:\n",
    "                ax.scatter(x0, y0, z0, color='b', s=80, marker='.', alpha=1.0)\n",
    "                \n",
    "    # label the axes\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "    ax.set_zlabel(\"PC3\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return pcaComponents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WTA buckets created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def WTA_PCA_SpaceVisualization(X,Prototypes,Labels,title='PCA visualization',withText=False,withgroundruth=False,groundruth=None,decompositionMenthod='PCA'):\n",
    "    '''\n",
    "    PCA to given array X and creating a plot\n",
    "    Returns PCA components array after fit_transform\n",
    "    '''\n",
    "    \n",
    "    # PCA code\n",
    "    if decompositionMenthod == 'PCA':\n",
    "        pca = PCA(n_components=2)\n",
    "    else:\n",
    "        pca = MDS(n_components=2)\n",
    "    pca.fit(X)\n",
    "    pcaComponents = pca.fit_transform(X) # pcaComponents is the data that I'll use from PCA\n",
    "    \n",
    "    # Seperating components\n",
    "    first_component = [x[0] for x in pcaComponents]\n",
    "    second_component = [x[1] for x in pcaComponents]\n",
    "    \n",
    "    # Plotting code\n",
    "    fig, ax = plt.subplots(figsize=(12,10))\n",
    "    cm = plt.get_cmap('jet') \n",
    "    \n",
    "    if not withgroundruth:\n",
    "        labels = [\",\".join(item) for item in Labels.astype(str)]\n",
    "        mydict={}\n",
    "        i = 0\n",
    "        for item in labels:\n",
    "            if(i>0 and item in mydict):\n",
    "                continue\n",
    "            else:    \n",
    "               i = i+1\n",
    "               mydict[item] = i\n",
    "\n",
    "        k=[]\n",
    "        for item in labels:\n",
    "            k.append(mydict[item])\n",
    "        \n",
    "    else:\n",
    "        k=groundruth\n",
    "\n",
    "    ax.scatter(first_component, second_component, c = k, cmap=cm, s=30) \n",
    "    fig.suptitle(title,fontsize=15,fontweight=\"bold\")\n",
    "    \n",
    "    if not withgroundruth:\n",
    "        for x0, y0, i in zip(first_component, second_component,range(0,len(first_component),1)):\n",
    "            if i in set(Prototypes):\n",
    "                plt.scatter(x0,y0,c='red',s=400,marker='*',alpha=0.2)\n",
    "    plt.show()\n",
    "    \n",
    "    return pcaComponents\n",
    "\n",
    "def WTA_PCA_SpaceVisualization_3D(X,Prototypes,Labels,title='PCA visualization',withText=False,withgroundruth=False,groundruth=None,decompositionMenthod='PCA'):\n",
    "    \n",
    "    # PCA code\n",
    "    if decompositionMenthod == 'PCA':\n",
    "        pca = PCA(n_components=3)\n",
    "    else:\n",
    "        pca = MDS(n_components=3)\n",
    "    pca.fit(X)\n",
    "    pcaComponents = pca.fit_transform(X) # pcaComponents is the data that I'll use from PCA\n",
    "    \n",
    "    # Seperating components\n",
    "    first_component = [x[0] for x in pcaComponents]\n",
    "    second_component = [x[1] for x in pcaComponents]\n",
    "    third_component = [x[2] for x in pcaComponents]\n",
    "\n",
    "    # Plotting code\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    cm = plt.get_cmap('jet') \n",
    "\n",
    "    if decompositionMenthod == 'PCA':\n",
    "        print(\"Explained varianse of PCA:\", pca.explained_variance_ratio_)\n",
    "\n",
    "    if not withgroundruth:\n",
    "        labels = [\",\".join(item) for item in Labels.astype(str)]\n",
    "        mydict={}\n",
    "        i = 0\n",
    "        for item in labels:\n",
    "            if(i>0 and item in mydict):\n",
    "                continue\n",
    "            else:    \n",
    "               i = i+1\n",
    "               mydict[item] = i\n",
    "\n",
    "        k=[]\n",
    "        for item in labels:\n",
    "            k.append(mydict[item])\n",
    "        \n",
    "    else:\n",
    "        k=groundruth\n",
    "\n",
    "    ax.scatter(first_component, second_component, third_component, c = k, cmap=cm, s=30) \n",
    "    fig.suptitle(title,fontsize=15,fontweight=\"bold\")\n",
    "    \n",
    "    if not withgroundruth:\n",
    "        for x0, y0, z0, i in zip(first_component, second_component, third_component, range(0,len(first_component),1)):\n",
    "            if i in set(Prototypes):\n",
    "                ax.scatter(x0,y0,z0,c='red',s=400,marker='*',alpha=0.2)\n",
    "                \n",
    "    # label the axes\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "    ax.set_zlabel(\"PC3\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return pcaComponents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype selection variance HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityProbsHeatMapWithClusters(similarityProb_matrix,clusters,title):\n",
    "    fif,ax = plt.subplots(1,figsize=(20,20))\n",
    "    colors = ['red','green','blue','yellow','orange']\n",
    "    c=0\n",
    "    for cl in clusters:\n",
    "        for i  in range(0,len(cl)):\n",
    "            for j in range(i+1,len(cl)):\n",
    "                ax.add_patch(Rectangle((cl[j],cl[i]), 1, 1, fill=False, edgecolor=colors[c], lw=3))\n",
    "        c+=1\n",
    "#     corr = np.corrcoef(ed_matrix)\n",
    "#     mask = np.zeros_like(corr)\n",
    "#     mask[np.tril_indices_from(mask)] = True\n",
    "    ax.set_title(title,fontsize=20,fontweight='bold')\n",
    "    ax = sns.heatmap(similarityProb_matrix, linewidth=0.5,annot=True,cmap=\"Blues\",fmt='.3g',ax=ax)\n",
    "    plt.show()\n",
    "    \n",
    "def similarityProbsHeatMap(similarityProb_matrix,title):\n",
    "    fif,ax = plt.subplots(1,figsize=(20,20))\n",
    "    ax.set_title(title,fontsize=20,fontweight='bold')\n",
    "    ax = sns.heatmap(similarityProb_matrix, linewidth=0.5,annot=True,cmap=\"Blues\",fmt='.3g',ax=ax)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigramms-Trigramms and jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('m', 'm', 's'), ('h', 'i', 's'), ('d', ' ', 't'), ('T', 'h', 'i'), ('a', 'n', ' '), ('l', 'e', ' '), (' ', 'b', 'i'), ('r', 'a', 'm'), ('x', 'a', 'm'), (' ', 't', 'r'), ('m', 's', '!'), ('o', 'f', ' '), (' ', 'a', 'n'), ('s', ' ', 'a'), ('b', 'i', 'g'), ('i', 's', ' '), ('n', 'd', ' '), ('g', 'r', 'a'), ('m', 's', ' '), (' ', 'o', 'f'), ('f', ' ', 'b'), ('e', ' ', 'o'), ('i', 'g', 'r'), (' ', 'e', 'x'), ('r', 'i', 'g'), (' ', 'i', 's'), ('m', 'p', 'l'), ('a', 'm', 'p'), ('p', 'l', 'e'), ('e', 'x', 'a'), ('a', 'n', 'd'), ('t', 'r', 'i'), ('n', ' ', 'e'), ('a', 'm', 'm'), ('s', ' ', 'i')}\n",
      "{('example', 'of', 'bigramms'), ('an', 'example', 'of'), ('of', 'bigramms', 'and'), ('This', 'is', 'an'), ('and', 'trigramms', '!'), ('bigramms', 'and', 'trigramms'), ('is', 'an', 'example')}\n",
      "0.0\n",
      "0.0\n",
      "1.0 1.0 1.0 1.0\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "sent = 'This is an example of bigramms and trigramms!'\n",
    "print(set(nltk.ngrams(sent, n=3)))\n",
    "print(set(nltk.ngrams(nltk.word_tokenize(sent), n=3)))\n",
    "print(nltk.jaccard_distance(set(nltk.ngrams(sent, n=3)),set(nltk.ngrams(sent, n=3))))\n",
    "print(nltk.jaccard_distance(set(nltk.ngrams(nltk.word_tokenize(sent), n=3)),set(nltk.ngrams(nltk.word_tokenize(sent), n=3))))\n",
    "\n",
    "s1 = \"m. ahlskog  j. paloheimo  h. stubb  p. dyreklev  m. fahlman  o. inganas and m.r.   andersson  nan j appl. phys.\"\n",
    "s2 = \"m. ahlskog  j. paloheimo  h. stubb  p. dyreklev  m. fahlman  o. inganas and m.r. andersson  j appl. phys. \"\n",
    "\n",
    "jc3 = jaccard(set(nltk.ngrams(s1, n=3)),set(nltk.ngrams(s2, n=3)))\n",
    "js3 = jaccard(set(nltk.ngrams(nltk.word_tokenize(s1), n=3)),set(nltk.ngrams(nltk.word_tokenize(s2), n=3)))\n",
    "jc2 = jaccard(set(nltk.ngrams(s1, n=2)),set(nltk.ngrams(s2, n=2)))\n",
    "js2 = jaccard(set(nltk.ngrams(nltk.word_tokenize(s1), n=2)),set(nltk.ngrams(nltk.word_tokenize(s2), n=2)))\n",
    "\n",
    "print(jc3,js3,jc2,js2)\n",
    "print(editdistance.eval(s1,s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __CORA Evaluation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row):\n",
    "\n",
    "    paper_str = \" \".join(row)\n",
    "\n",
    "    # Lower letters \n",
    "    paper_str = paper_str.lower()\n",
    "    \n",
    "    # Remove unwanted chars \n",
    "    paper_str = paper_str.replace(\"\\n\", \" \").replace(\"/z\", \" \")\n",
    "    \n",
    "    # Remove pancutation     \n",
    "    paper_str = paper_str.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    return str(paper_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Id</th>\n",
       "      <th>address</th>\n",
       "      <th>author</th>\n",
       "      <th>editor</th>\n",
       "      <th>institution</th>\n",
       "      <th>month</th>\n",
       "      <th>note</th>\n",
       "      <th>pages</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88</td>\n",
       "      <td>bari, italy:</td>\n",
       "      <td>dietterich, t., m. kearns, and y.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan kaufmann.</td>\n",
       "      <td>mansour (1996). applying the weak learning fra...</td>\n",
       "      <td>to appear in proceedings of the thirteenth int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d. haussler, m. kearns, n. littlestone, m. war...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and university of california at santa cruz inf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pp. 42-55,</td>\n",
       "      <td>morgan kaufmann publishers,</td>\n",
       "      <td>equivalence of models for polynomial learnabil...</td>\n",
       "      <td>technical report number ucsc-crl-88-06,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>freund, y. &amp; schapire, r. e.</td>\n",
       "      <td>in l. saitta, ed.,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pp. 148-156.</td>\n",
       "      <td>morgan kaufmann,</td>\n",
       "      <td>experiments with a new boosting algorithm,</td>\n",
       "      <td>`machine learning: proceedings of the thirteen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1996),</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>oxford, 1994.</td>\n",
       "      <td>n. cesa-bianchi, y. freund, d. p. helm-bold, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pages 205-216,</td>\n",
       "      <td>oxford university press.</td>\n",
       "      <td>on-line prediction and conversion strategies.</td>\n",
       "      <td>in computational learning theory: eurocolt '93...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r. e. schapire.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pages 313-321.</td>\n",
       "      <td>morgan kaufmann,</td>\n",
       "      <td>using output codes to boost multiclass learnin...</td>\n",
       "      <td>in machine learning: proceedings of the fourte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>david p. helmbold, robert e. schapire, yoram s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pages 69-78,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a comparison of new and old algorithms for a m...</td>\n",
       "      <td>in proceedings of the eighth annual conference...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>robert e. schapire.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>january</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>private correspondence,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>david haussler, michael kearns, and robert e. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83-113,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bounds on the sample complexity of bayesian le...</td>\n",
       "      <td>machine learning,</td>\n",
       "      <td>14</td>\n",
       "      <td>1994.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m.j. kearns.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>efficient noise-tolerant learning from statist...</td>\n",
       "      <td>proceedings of the 25th acm symposium on the t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1254</td>\n",
       "      <td>san francisco, ca,</td>\n",
       "      <td>r. e. schapire and m. k. warmuth.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>july</td>\n",
       "      <td>morgan kaufmann. to appear in machine learning.</td>\n",
       "      <td>pages 266-274,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on the worst-case analysis of temporal-differe...</td>\n",
       "      <td>in proc. 11th international conf. on machine l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1295 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Entity Id             address  \\\n",
       "0            88        bari, italy:   \n",
       "1           493                 NaN   \n",
       "2           348                 NaN   \n",
       "3            62       oxford, 1994.   \n",
       "4          1285                 NaN   \n",
       "...         ...                 ...   \n",
       "1290        595                 NaN   \n",
       "1291       1248                 NaN   \n",
       "1292        583                 NaN   \n",
       "1293        860                 NaN   \n",
       "1294       1254  san francisco, ca,   \n",
       "\n",
       "                                                 author              editor  \\\n",
       "0                     dietterich, t., m. kearns, and y.                 NaN   \n",
       "1     d. haussler, m. kearns, n. littlestone, m. war...                 NaN   \n",
       "2                          freund, y. & schapire, r. e.  in l. saitta, ed.,   \n",
       "3     n. cesa-bianchi, y. freund, d. p. helm-bold, a...                 NaN   \n",
       "4                                       r. e. schapire.                 NaN   \n",
       "...                                                 ...                 ...   \n",
       "1290  david p. helmbold, robert e. schapire, yoram s...                 NaN   \n",
       "1291                                robert e. schapire.                 NaN   \n",
       "1292  david haussler, michael kearns, and robert e. ...                 NaN   \n",
       "1293                                       m.j. kearns.                 NaN   \n",
       "1294                  r. e. schapire and m. k. warmuth.                 NaN   \n",
       "\n",
       "                                            institution    month  \\\n",
       "0                                                   NaN      NaN   \n",
       "1     and university of california at santa cruz inf...      NaN   \n",
       "2                                                   NaN      NaN   \n",
       "3                                                   NaN      NaN   \n",
       "4                                                   NaN      NaN   \n",
       "...                                                 ...      ...   \n",
       "1290                                                NaN      NaN   \n",
       "1291                                                NaN  january   \n",
       "1292                                                NaN      NaN   \n",
       "1293                                                NaN      NaN   \n",
       "1294                                                NaN     july   \n",
       "\n",
       "                                                 note           pages  \\\n",
       "0                                                 NaN             NaN   \n",
       "1                                                 NaN      pp. 42-55,   \n",
       "2                                                 NaN    pp. 148-156.   \n",
       "3                                                 NaN  pages 205-216,   \n",
       "4                                                 NaN  pages 313-321.   \n",
       "...                                               ...             ...   \n",
       "1290                                              NaN    pages 69-78,   \n",
       "1291                                              NaN             NaN   \n",
       "1292                                              NaN         83-113,   \n",
       "1293                                              NaN             NaN   \n",
       "1294  morgan kaufmann. to appear in machine learning.  pages 266-274,   \n",
       "\n",
       "                        publisher  \\\n",
       "0                morgan kaufmann.   \n",
       "1     morgan kaufmann publishers,   \n",
       "2                morgan kaufmann,   \n",
       "3        oxford university press.   \n",
       "4                morgan kaufmann,   \n",
       "...                           ...   \n",
       "1290                          NaN   \n",
       "1291                          NaN   \n",
       "1292                          NaN   \n",
       "1293                          NaN   \n",
       "1294                          NaN   \n",
       "\n",
       "                                                  title  \\\n",
       "0     mansour (1996). applying the weak learning fra...   \n",
       "1     equivalence of models for polynomial learnabil...   \n",
       "2            experiments with a new boosting algorithm,   \n",
       "3         on-line prediction and conversion strategies.   \n",
       "4     using output codes to boost multiclass learnin...   \n",
       "...                                                 ...   \n",
       "1290  a comparison of new and old algorithms for a m...   \n",
       "1291                            private correspondence,   \n",
       "1292  bounds on the sample complexity of bayesian le...   \n",
       "1293  efficient noise-tolerant learning from statist...   \n",
       "1294  on the worst-case analysis of temporal-differe...   \n",
       "\n",
       "                                                  venue volume     year  \\\n",
       "0     to appear in proceedings of the thirteenth int...    NaN      NaN   \n",
       "1               technical report number ucsc-crl-88-06,    NaN    1988.   \n",
       "2     `machine learning: proceedings of the thirteen...    NaN  (1996),   \n",
       "3     in computational learning theory: eurocolt '93...    NaN      NaN   \n",
       "4     in machine learning: proceedings of the fourte...    NaN    1997.   \n",
       "...                                                 ...    ...      ...   \n",
       "1290  in proceedings of the eighth annual conference...    NaN    1995.   \n",
       "1291                                                NaN    NaN    1992.   \n",
       "1292                                  machine learning,     14    1994.   \n",
       "1293  proceedings of the 25th acm symposium on the t...    NaN    1993.   \n",
       "1294  in proc. 11th international conf. on machine l...    NaN    1994.   \n",
       "\n",
       "      Unnamed: 13  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "...           ...  \n",
       "1290          NaN  \n",
       "1291          NaN  \n",
       "1292          NaN  \n",
       "1293          NaN  \n",
       "1294          NaN  \n",
       "\n",
       "[1295 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORA_shuffled = CORA.sample(frac=1).reset_index(drop=True)\n",
    "CORA_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CORA dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cora_createDataset(cora_dataframe, true_values, fields, id_column, keepNone = False, preprocessEnabled=True):\n",
    "\n",
    "    rawStr_col = []\n",
    "    index_to_id_dict = {}\n",
    "    sameEntities_dictionary = {}\n",
    "\n",
    "    i=0\n",
    "    for _, row in tqdm(cora_dataframe.iterrows()):\n",
    "        index_to_id_dict[int(row[id_column])] = i\n",
    "        rawStr = []\n",
    "        for field in fields:\n",
    "            if (isna(row[field]) and keepNone == True) or (keepNone == False and not isna(row[field])):\n",
    "                rawStr.append(str(row[field]))\n",
    "        i+=1\n",
    "        if preprocessEnabled:\n",
    "            rawStr_col.append(preprocess(rawStr))\n",
    "        else:\n",
    "            rawStr_col.append(rawStr)\n",
    "            \n",
    "    num_of_records = len(cora_dataframe)\n",
    "    trueValues_matrix = np.zeros([num_of_records,num_of_records],dtype=np.int8)\n",
    "\n",
    "    for _, row in tqdm(true_values.iterrows()):  \n",
    "        trueValues_matrix[index_to_id_dict[row['id1']]][index_to_id_dict[row['id2']]] = 1\n",
    "        trueValues_matrix[index_to_id_dict[row['id2']]][index_to_id_dict[row['id1']]] = 1\n",
    "\n",
    "    return rawStr_col, trueValues_matrix\n",
    "\n",
    "def isna(value):\n",
    "    if isinstance(value, float) and math.isnan(value):\n",
    "        return True \n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def create_trueLabels(idColumn,groundTruth):\n",
    "    data = list(zip(groundTruth.id1, groundTruth.id2))\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(data)\n",
    "    groups = list(nx.connected_components(G))\n",
    "    newId = len(groups)\n",
    "    labels_groundTruth = np.empty([len(idColumn)], dtype=int)\n",
    "    for tid in idColumn:\n",
    "        for g,g_index in zip(groups,range(0,len(groups),1)):\n",
    "            if tid in g:\n",
    "                labels_groundTruth[tid] = g_index\n",
    "\n",
    "        if labels_groundTruth[tid] not in range(0,len(groups),1):\n",
    "            labels_groundTruth[tid] = newId\n",
    "            newId+=1\n",
    "            \n",
    "    return labels_groundTruth,newId,groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0868d0cf25704171933e17c2a77c3d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d75ff21b01b4f13883fc0462620c4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fields = [\n",
    "     'address',\n",
    "     'author',\n",
    "     'editor',\n",
    "     'institution',\n",
    "     'month',\n",
    "     'note',\n",
    "     'pages',\n",
    "     'publisher',\n",
    "     'title',\n",
    "     'venue',\n",
    "     'volume',\n",
    "     'year',\n",
    "     'Unnamed: 13'\n",
    "]\n",
    "\n",
    "# fields = [\n",
    "#      'author',\n",
    "#      'title',\n",
    "# ]\n",
    "\n",
    "\n",
    "# CORA\n",
    "# data, true_matrix = cora_createDataset(CORA, CORA_groundTruth, fields, 'Entity Id')\n",
    "\n",
    "# Toy CORA\n",
    "data, true_matrix = cora_createDataset(CORA.head(15), CORA_groundTruth.head(50), fields, 'Entity Id')\n",
    "\n",
    "# Old CORA\n",
    "# data, true_matrix = cora_createDataset(CORA1, CORA1_groundTruth, fields, '@id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_groundTruth, numOfObjWithoutDups, groups = create_trueLabels(CORA['Entity Id'].tolist(),CORA_groundTruth)            \n",
    "data_length = [ len(x) for x in data ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORA specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Spec</th>        <th class=\"col_heading level0 col1\" >#number</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row0_col0\" class=\"data row0 col0\" >Objects without any duplicates</td>\n",
       "                        <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row0_col1\" class=\"data row0 col1\" >19</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row1_col0\" class=\"data row1 col0\" >Objects with at least one duplicate</td>\n",
       "                        <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row1_col1\" class=\"data row1 col1\" >1276</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row2_col0\" class=\"data row2 col0\" >Total number of objects</td>\n",
       "                        <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row2_col1\" class=\"data row2 col1\" >1295</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row3_col0\" class=\"data row3 col0\" >Number of ER clusters</td>\n",
       "                        <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row3_col1\" class=\"data row3 col1\" >93</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row4_col0\" class=\"data row4 col0\" >Dataset size</td>\n",
       "                        <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row4_col1\" class=\"data row4 col1\" >1295</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row5_col0\" class=\"data row5 col0\" >Average length</td>\n",
       "                        <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row5_col1\" class=\"data row5 col1\" >164</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row6_col0\" class=\"data row6 col0\" >Min length</td>\n",
       "                        <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row6_col1\" class=\"data row6 col1\" >38</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row7_col0\" class=\"data row7 col0\" >Max length</td>\n",
       "                        <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row7_col1\" class=\"data row7 col1\" >366</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row8_col0\" class=\"data row8 col0\" >Median length</td>\n",
       "                        <td id=\"T_10484c00_4c33_11ec_8c07_4074e08dca88row8_col1\" class=\"data row8 col1\" >164</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2339d075548>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs = {\n",
    "    'Objects without any duplicates' : numOfObjWithoutDups-len(groups), \n",
    "    'Objects with at least one duplicate' : sum([len(x) for x in groups]),\n",
    "    'Total number of objects' : CORA.shape[0], \n",
    "    'Number of ER clusters' : len(groups),\n",
    "    'Dataset size' : len(data), \n",
    "    'Average length' : np.mean(data_length), \n",
    "    'Min length' : min(data_length), \n",
    "    'Max length' : max(data_length), \n",
    "    'Median length' : np.median(data_length)\n",
    "}\n",
    "\n",
    "specsCoraDf = pd.DataFrame(list(specs.items()), columns=['Spec','#number'])\n",
    "specsCoraDf[['#number']] = specsCoraDf[['#number']].astype(int)\n",
    "specsCoraDf.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Dataset attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Entity Id',\n",
       " 'address',\n",
       " 'author',\n",
       " 'editor',\n",
       " 'institution',\n",
       " 'month',\n",
       " 'note',\n",
       " 'pages',\n",
       " 'publisher',\n",
       " 'title',\n",
       " 'venue',\n",
       " 'volume',\n",
       " 'year',\n",
       " 'Unnamed: 13']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(CORA.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(range(0,len(data_length),1),data_length)\n",
    "plt.xlabel(\"Record index\")\n",
    "plt.ylabel(\"String length\")\n",
    "plt.title(\"StrLength\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe = pd.DataFrame(columns=['max_numberOf_clusters','max_editDistance','similarityThreshold','windowSize','metric','similarityVectors',\"distanceMetricEmbedding\",\"distanceMetric\",\"number_of_permutations\",\"ngramms\",\"jaccard_with_chars\",'Accuracy','Precision','Recall','F1','Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORA: Best Jaccard execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#####################################################################\n",
      "#     .~ RankedWTAHash with Vantage embeddings starts training ~.   #\n",
      "#####################################################################\n",
      "\n",
      "###########################################################\n",
      "# > 1. Prototype selection phase                          #\n",
      "###########################################################\n",
      "\n",
      "\n",
      "-> Finding prototypes and representatives of each cluster:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e8eb6f416c4e1b9869bd23a9b89031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "- Final number of prototypes:  3\n",
      "\n",
      "# Finished in 0.0540 secs\n",
      "\n",
      "\n",
      "###########################################################\n",
      "# > 2. Embeddings based on the Vantage objects            #\n",
      "###########################################################\n",
      "\n",
      "\n",
      "-> Creating Embeddings:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a9f0b7f3aa474cada623463292e3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Embeddings created\n",
      "\n",
      "# Finished in 0.0430 secs\n",
      "\n",
      "\n",
      "###########################################################\n",
      "# > 3. WTA Hashing                                        #\n",
      "###########################################################\n",
      "\n",
      "\n",
      "-> Creating WTA Buckets:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikol\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:520: UserWarning: Window size greater than vector dimension\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dedfd2b032249f9ae02b7dce6957958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "- WTA number of buckets:  2\n",
      "\n",
      "# Finished in 0.0529 secs\n",
      "\n",
      "\n",
      "###########################################################\n",
      "# > 4. Similarity checking                                #\n",
      "###########################################################\n",
      "\n",
      "\n",
      "-> Similarity checking:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9528c91df0fe4f6fbf147308ac41013e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# Finished in 0.1109 secs\n",
      "\n",
      "#####################################################################\n",
      "#                           .~  End  ~.                             #\n",
      "#####################################################################\n",
      "\n",
      "#####################################################################\n",
      "#                          Evaluation                               #\n",
      "#####################################################################\n",
      "\n",
      "Accuracy:  93.33 %\n",
      "F1-Score:  91.30 %\n",
      "Recall:    84.00 %\n",
      "Precision: 100.00 %\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        70\n",
      "           1       1.00      0.84      0.91        50\n",
      "\n",
      "    accuracy                           0.93       120\n",
      "   macro avg       0.95      0.92      0.93       120\n",
      "weighted avg       0.94      0.93      0.93       120\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "--- DETAILED REPORT ---\n",
      "\n",
      "\n",
      "\n",
      "> 1. Prototype selection\n",
      "\n",
      "\n",
      "> 2. Embedding phase\n",
      "\n",
      "\n",
      "> 3. WTA hashing\n",
      "\n",
      "Number of buckets created  2\n",
      "[0]  ->  2\n",
      "[2]  ->  13\n",
      "\n",
      "> 4. Similarity checking\n",
      "\n",
      "Total comparisons:  79\n",
      " -> between same objects:  42\n",
      " -> between same objects with success:  42\n",
      " -> between different objects with success:  37\n",
      "Wall time: 652 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ngramms= 3                                  # If jaccard used, n-gramms are used\n",
    "jaccard_withchars = True                    # n-gramms either of chars and either of words\n",
    "\n",
    "# Prototype selection\n",
    "max_numberOf_clusters= 1000                  # Νumber of loops for finding representatives, it is an upper bound of clusters.\n",
    "max_dissimilarityDistance= 0.5                       # The threshold for the triangle inequality\n",
    "distanceMetric= 'jaccard'                   # Distance metric between the strings when creating the space\n",
    "prototypesFilterThr = 0.6                   # Prototypes must differ more than that threshold\n",
    "\n",
    "# Embedding phase\n",
    "distanceMetricEmbedding = 'euclid_jaccard'  # Embedding metric\n",
    "\n",
    "# WTA algorithm\n",
    "windowSize = 70                           # Vector size for WTA algo\n",
    "number_of_permutations = 1                # WTA number of permutations\n",
    "\n",
    "# Similarity evaluation\n",
    "similarityVectors='ranked'                  # which vectors will be passed to WTA step\n",
    "similarityThreshold= 0.6                    # Similarity threshold for the final step\n",
    "metric='kendal'                             # Similarity metric between vectors\n",
    "\n",
    "start = time.time()\n",
    "model = RankedWTAHash(\n",
    "    max_numberOf_clusters= max_numberOf_clusters,\n",
    "    max_dissimilarityDistance= max_dissimilarityDistance,\n",
    "    windowSize= windowSize,\n",
    "    similarityThreshold= similarityThreshold,\n",
    "    metric=metric,\n",
    "    similarityVectors=similarityVectors,\n",
    "    number_of_permutations = number_of_permutations,\n",
    "    distanceMetric= distanceMetric,\n",
    "    distanceMetricEmbedding = distanceMetricEmbedding,\n",
    "    ngramms= ngramms,\n",
    "    jaccard_withchars = jaccard_withchars,\n",
    "    prototypesFilterThr = prototypesFilterThr,\n",
    "    verboseLevel = 0\n",
    ")\n",
    "model = model.fit(data)\n",
    "acc,f1,precision,recall = evaluate(model.mapping_matrix, true_matrix, True)\n",
    "report(model)\n",
    "exec_time = time.time() - start\n",
    "results_dataframe.loc[len(results_dataframe)+1] = [max_numberOf_clusters,max_dissimilarityDistance,similarityThreshold,windowSize,metric,similarityVectors,distanceMetricEmbedding,distanceMetric,number_of_permutations,ngramms,jaccard_withchars,acc,precision,recall,f1,exec_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 2],\n",
       "       [3, 1, 2],\n",
       "       [3, 1, 2],\n",
       "       [3, 1, 2],\n",
       "       [3, 1, 2],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [2, 3, 1]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_numberOf_clusters</th>\n",
       "      <th>max_editDistance</th>\n",
       "      <th>similarityThreshold</th>\n",
       "      <th>windowSize</th>\n",
       "      <th>metric</th>\n",
       "      <th>similarityVectors</th>\n",
       "      <th>distanceMetricEmbedding</th>\n",
       "      <th>distanceMetric</th>\n",
       "      <th>number_of_permutations</th>\n",
       "      <th>ngramms</th>\n",
       "      <th>jaccard_with_chars</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [max_numberOf_clusters, max_editDistance, similarityThreshold, windowSize, metric, similarityVectors, distanceMetricEmbedding, distanceMetric, number_of_permutations, ngramms, jaccard_with_chars, Accuracy, Precision, Recall, F1, Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CORA: Best Edit distance execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RankedWTAHash' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RankedWTAHash' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Prototype selection\n",
    "max_numberOf_clusters= 1000                  # Νumber of loops for finding representatives, it is an upper bound of clusters.\n",
    "max_dissimilarityDistance= 100                       # The threshold for the triangle inequality\n",
    "distanceMetric= 'edit'                   # Distance metric between the vectors when creating the space\n",
    "prototypesFilterThr = 100                # Prototypes must differ more that threshold\n",
    "\n",
    "# Embedding phase\n",
    "distanceMetricEmbedding = 'l_inf'  # Embedding metric\n",
    "\n",
    "# WTA algorithm\n",
    "windowSize= 37                             # Vector size for WTA algo\n",
    "number_of_permutations = 3                 # WTA number of permutations\n",
    "\n",
    "\n",
    "# Similarity evaluation\n",
    "similarityVectors='initial'                  # which vectors will be passed to WTA step\n",
    "similarityThreshold= 0.7                    # Similarity threshold for the final step\n",
    "metric='kendal'                             # Similarity metric between vectors\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model = RankedWTAHash(\n",
    "    max_numberOf_clusters= max_numberOf_clusters,    \n",
    "    max_dissimilarityDistance= max_dissimilarityDistance,    \n",
    "    windowSize= windowSize,    \n",
    "    similarityThreshold= similarityThreshold,    \n",
    "    metric= metric,    \n",
    "    similarityVectors=similarityVectors,    \n",
    "    number_of_permutations = number_of_permutations,\n",
    "    distanceMetric= distanceMetric,\n",
    "    distanceMetricEmbedding = distanceMetricEmbedding,\n",
    "    ngramms= ngramms,\n",
    "    jaccard_withchars = jaccard_withchars,\n",
    "    prototypesFilterThr = prototypesFilterThr\n",
    ")\n",
    "model = model.fit(data)\n",
    "acc,f1,precision,recall = evaluate(model.mapping_matrix,true_matrix, True)\n",
    "exec_time = time.time() - start\n",
    "results_dataframe.loc[len(results_dataframe)+1] = [max_numberOf_clusters,max_dissimilarityDistance,similarityThreshold,windowSize,metric,similarityVectors,distanceMetricEmbedding,distanceMetric,number_of_permutations,ngramms,jaccard_withchars,acc,precision,recall,f1,exec_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-09e3046ce61f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpcaComponents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA_SpaceVisualization_3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbeddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprototypeArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pcaComponents = PCA_SpaceVisualization_3D(model.Embeddings,model.prototypeArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaComponents = PCA_SpaceVisualization_3D(model.rankedVectors,model.prototypeArray, decompositionMenthod='MSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaComponents = WTA_PCA_SpaceVisualization_3D(model.rankedVectors,model.prototypeArray,model.HashedClusters, decompositionMenthod='MSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaComponents = WTA_PCA_SpaceVisualization_3D(model.rankedVectors,model.prototypeArray,model.HashedClusters,withgroundruth=True,groundruth=labels_groundTruth,title='MSD visualization GroundTruth', decompositionMenthod='MSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaComponents = WTA_PCA_SpaceVisualization_3D(model.rankedVectors,model.prototypeArray,model.HashedClusters,withgroundruth=True,groundruth=labels_groundTruth,title='PCA visualization GroundTruth', decompositionMenthod='PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMD${}^2$ error between distribution of Prototypes and whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMMD2(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search each section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GridSearch_cora(data,true_matrix,max_numberOf_clusters,max_dissimilarityDistance,similarityThreshold,windowSize,metric,similarityVectors,distanceMetricEmbedding,distanceMetric,number_of_permutations,ngramms,withchars,prototypeFilter,earlyStop):\n",
    "    results_dataframe = pd.DataFrame(columns=['max_numberOf_clusters','max_dissimilarityDistance','similarityThreshold','windowSize','metric','similarityVectors',\"distanceMetricEmbedding\",\"distanceMetric\",\"number_of_permutations\",'prototypesFilterThr',\"protSelectionVariance\",'numOfPrototypes','numOfBuckets','averageBucketSize','Accuracy','Precision','Recall','F1','Time'])\n",
    "    i=1\n",
    "    for n1 in tqdm(max_numberOf_clusters):\n",
    "        for n2 in (max_dissimilarityDistance):\n",
    "            for n3 in (similarityThreshold):\n",
    "                for n4 in (windowSize):\n",
    "                    for n5 in (metric):\n",
    "                        for n6 in (similarityVectors):\n",
    "                            for n7 in (distanceMetricEmbedding):\n",
    "                                for n8 in (distanceMetric):\n",
    "                                    for n9 in (number_of_permutations):\n",
    "                                        for n10 in (withchars):\n",
    "                                            for n11 in (withchars):\n",
    "                                                for n12 in (prototypeFilter):\n",
    "                                                    print(\"+ ------------  \",i,\"   ------------- +\")\n",
    "                                                    print('max_numberOf_clusters: ',n1)\n",
    "                                                    print('max_dissimilarityDistance: ',n2)\n",
    "                                                    print('similarityThreshold: ',n3)\n",
    "                                                    print('windowSize: ',n4)\n",
    "                                                    print('metric: ',n5)\n",
    "                                                    print('similarityVectors: ',n6)\n",
    "                                                    print('distanceMetricEmbedding: ',n7)\n",
    "                                                    print('distanceMetric: ',n8)\n",
    "                                                    print('number_of_permutations: ',n9)\n",
    "                                                    print('withchars: ',n10)\n",
    "                                                    print('ngramms: ',n11)\n",
    "                                                    print('prototypeFilter: ',n12)\n",
    "                                                    print(\"+ ----------------------------------- +\")\n",
    "                                                    start = time.time()\n",
    "                                                    model = RankedWTAHash(\n",
    "                                                      earlyStop = earlyStop,\n",
    "                                                      max_numberOf_clusters= n1,\n",
    "                                                      max_dissimilarityDistance= n2,\n",
    "                                                      windowSize= n4,\n",
    "                                                      similarityThreshold= n3,\n",
    "                                                      maxOnly= False,\n",
    "                                                      metric=n5,\n",
    "                                                      similarityVectors=n6,\n",
    "                                                      number_of_permutations = n9,\n",
    "                                                      distanceMetric= n8,\n",
    "                                                      distanceMetricEmbedding = n7,\n",
    "                                                      jaccard_withchars = n10,\n",
    "                                                      ngramms= n11,                                                      \n",
    "                                                      prototypesFilterThr = n12\n",
    "                                                    )\n",
    "                                                    model = model.fit(data)\n",
    "                                                    exec_time = time.time() - start\n",
    "                                                    if model.earlyStop==0:                                            \n",
    "                                                        acc,f1,precision,recall = evaluate(model.mapping_matrix,true_matrix)\n",
    "                                                        for key in model.buckets.keys():\n",
    "                                                            tempListmodel.buckets[key]\n",
    "                                                        averageBucketSize = np.mean([len(model.buckets[x]) for x in model.buckets.keys() ])\n",
    "                                                        numOfBuckets=len(model.buckets.keys())\n",
    "                                                    else:\n",
    "                                                        if model.earlyStop == 3:\n",
    "                                                            acc = f1 = precision = recall = 'Not counted'\n",
    "                                                            averageBucketSize = np.mean([len(model.buckets[x]) for x in model.buckets.keys() ])\n",
    "                                                            numOfBuckets=len(model.buckets.keys())\n",
    "                                                        else:\n",
    "                                                            numOfBuckets = averageBucketSize = acc = f1 = precision = recall = 'Not counted'\n",
    "                                                    i+=1\n",
    "                                                    results_dataframe.loc[len(results_dataframe)+1] = [n1,n2,n3,n4,n5,n6,n7,n8,n9,n12,model.selectionVariance,model.selected_numOfPrototypes,numOfBuckets,averageBucketSize,acc,precision,recall,f1,exec_time]\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H_%M_%S\")\n",
    "    results_dataframe.to_pickle(str(current_time)+\".pkl\")\n",
    "    \n",
    "    return results_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### __[i]__ __Prototype selection__\n",
    "\n",
    "\n",
    "First of all, we need to find some ways on evaluating the prototype selection algorithm. Vantage Spaces are not something new, but we need to examine its behaviour on CORA dataset.\n",
    "\n",
    "Goals:\n",
    "\n",
    "- __Variance__: We want prototypes to be as much different as possible. \n",
    "- __Number__: We need a large amount of prototypes.\n",
    "\n",
    "Ways to evaluate the algorithm:\n",
    "\n",
    "- Mean distance between selected prototypes\n",
    "- Show a HeatMap of consisted of the distances\n",
    "- Some greedy search on the parameters. Parameters to fine tunne:\n",
    "    -  ```max_numberOf_clusters```: Νumber of loops for finding representatives, it is an upper bound of clusters.\n",
    "    -  ```max_dissimilarityDistance```:  The threshold for the triangle inequality\n",
    "    -  ```distanceMetric```:  Distance metric between the vectors when creating the space\n",
    "    -  ```prototypesFilterThr```: Prototypes must differ more that threshold\n",
    "\n",
    "\n",
    "All these parameters will be tested both for edit distance and jaccard with 3-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "__Maximum mean discrepancy (MMD)__, which measures the discrepancy between two distributions. The selection of prototypes creates a density distribution of prototypes. We want to evaluate whether the prototypes distribution differs from the data distribution. We estimate both with kernel density functions. The maximum mean discrepancy measures the difference between two distributions, which is the supremum over a function space of differences between the expectations according to the two distributions. All clear? Personally, I understand these concepts much better when I see how something is calculated with data. The following formula shows how to calculate the squared MMD measure (MMD2):\n",
    "    $$\n",
    "    MMD^2=\\frac{1}{m^2}\\sum_{i,j=1}^m{}k(z_i,z_j)-\\frac{2}{mn}\\sum_{i,j=1}^{m,n}k(z_i,x_j)+\\frac{1}{n^2}\\sum_{i,j=1}^n{}k(x_i,x_j)\n",
    "    $$\n",
    "    \n",
    "- __k__ is a kernel function that measures the similarity of two points\n",
    "- __m__ is the number of prototypes \n",
    "- __n__ is the number of data points x in our original dataset. \n",
    "- The prototypes z are a selection of data points x. \n",
    "\n",
    "    \n",
    "Each point is multidimensional, that is it can have multiple features. The goal of MMD-critic is to minimize MMD2. The closer MMD2 is to zero, the better the distribution of the prototypes fits the data. The key to bringing MMD2 down to zero is the term in the middle, which calculates the average proximity between the prototypes and all other data points (multiplied by 2). If this term adds up to the first term (the average proximity of the prototypes to each other) plus the last term (the average proximity of the data points to each other), then the prototypes explain the data perfectly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def myMMD2(model):    \n",
    "    mmdOnPrototypes = MMD2(model.dissimilarityDistance, model.S_index, model.prototypeArray)\n",
    "    print(\"MMD2: \",mmdOnPrototypes)        \n",
    "        \n",
    "        \n",
    "def MMD2(k, x, z):\n",
    "    \n",
    "    if type(x) is np.ndarray and type(z) is np.ndarray:\n",
    "        m = z.size\n",
    "        n = x.size\n",
    "    else:\n",
    "        m = len(z)\n",
    "        n = len(x)\n",
    "        \n",
    "    firstSum = 0.0\n",
    "    for i in range(0,m,1):\n",
    "        for j in range(0,m,1):\n",
    "            firstSum += k(z[i],z[j])\n",
    "    \n",
    "    secondSum = 0.0\n",
    "    for i in range(0,m,1):\n",
    "        for j in range(0,n,1):\n",
    "            secondSum += k(z[i],x[j])\n",
    "        \n",
    "    thirdSum = 0.0\n",
    "    for i in range(0,n,1):\n",
    "        for j in range(0,n,1):\n",
    "            thirdSum += k(x[i],x[j])\n",
    "    \n",
    "    mmd2 = (1/pow(m,2))*firstSum - (2/(m*n))*secondSum + (1/pow(n,2))*thirdSum\n",
    "    \n",
    "    \n",
    "    return mmd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_numberOf_clusters= [5000]\n",
    "max_dissimilarityDistance= [20]\n",
    "prototypesFilterThr = [80]\n",
    "\n",
    "distanceMetric= ['edit']\n",
    "\n",
    "# ---------------- #\n",
    "\n",
    "ngramms= [3]  \n",
    "jaccard_withchars = [False] \n",
    "\n",
    "distanceMetricEmbedding = ['euclidean']\n",
    "\n",
    "windowSize= [50]\n",
    "number_of_permutations = [5]\n",
    "\n",
    "similarityThreshold= [0.7]\n",
    "similarityVectors= ['ranked']\n",
    "metric= ['kendal']\n",
    "\n",
    "results_section1_edit = GridSearch_cora(\n",
    "    data,true_matrix,\n",
    "    max_numberOf_clusters,\n",
    "    max_dissimilarityDistance,\n",
    "    similarityThreshold,\n",
    "    windowSize,\n",
    "    metric,\n",
    "    similarityVectors,\n",
    "    distanceMetricEmbedding,\n",
    "    distanceMetric,\n",
    "    number_of_permutations,\n",
    "    ngramms,\n",
    "    jaccard_withchars,\n",
    "    prototypesFilterThr,\n",
    "    earlyStop=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_numberOf_clusters= [100,500,1000]\n",
    "max_dissimilarityDistance= [0.7,0.8]\n",
    "prototypesFilterThr = [0.2,0.3]\n",
    "\n",
    "distanceMetric= ['jaccard']\n",
    "\n",
    "\n",
    "ngramms= [2,3]  \n",
    "jaccard_withchars = [True] \n",
    "\n",
    "# ---------------- #\n",
    "\n",
    "distanceMetricEmbedding = ['euclidean']\n",
    "\n",
    "windowSize= [50]\n",
    "number_of_permutations = [5]\n",
    "\n",
    "similarityThreshold= [0.7]\n",
    "similarityVectors= ['ranked']\n",
    "metric= ['kendal']\n",
    "\n",
    "\n",
    "results_section1_jac = GridSearch_cora(\n",
    "    data,true_matrix,\n",
    "    max_numberOf_clusters,\n",
    "    max_dissimilarityDistance,\n",
    "    similarityThreshold,\n",
    "    windowSize,\n",
    "    metric,\n",
    "    similarityVectors,\n",
    "    distanceMetricEmbedding,\n",
    "    distanceMetric,\n",
    "    number_of_permutations,\n",
    "    ngramms,\n",
    "    jaccard_withchars,\n",
    "    prototypesFilterThr,\n",
    "    earlyStop=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Remarks\n",
    "\n",
    "Two main factors:\n",
    "\n",
    "- __numOfPrototypes__ and\n",
    "- __protSelectionVariance__\n",
    "\n",
    "The first one is the number of prototypes selected, which is very important as more prototypes will enhance model when creating the embeddings.\n",
    "\n",
    "The second one is the average distance between all the prototypes selected. As this factor increases, the prototypes selected differ the most.\n",
    "\n",
    "\n",
    "According to the above, best parameters so far:\n",
    "\n",
    "- __Edit distance__\n",
    "\n",
    "\n",
    "- __Jaccard with 3-grams__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### __[ii]__ Fine tunning  __Embedding phase__\n",
    "\n",
    "Ways to evaluate the __Embedding phase__:\n",
    "\n",
    "- Use a PCA after embeddings made and check selected prototypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_numberOf_clusters= [5000]\n",
    "max_dissimilarityDistance= [20,50]\n",
    "prototypesFilterThr = [80]\n",
    "\n",
    "distanceMetric= ['edit']\n",
    "\n",
    "# ---------------- #\n",
    "\n",
    "ngramms= [3]  \n",
    "jaccard_withchars = [False] \n",
    "\n",
    "distanceMetricEmbedding = ['euclidean','l_inf','edit']\n",
    "\n",
    "windowSize= [50]\n",
    "number_of_permutations = [5]\n",
    "\n",
    "similarityThreshold= [0.7]\n",
    "similarityVectors= ['ranked']\n",
    "metric= ['kendal']\n",
    "\n",
    "results_section1_edit = GridSearch_cora(\n",
    "    data,true_matrix,\n",
    "    max_numberOf_clusters,\n",
    "    max_dissimilarityDistance,\n",
    "    similarityThreshold,\n",
    "    windowSize,\n",
    "    metric,\n",
    "    similarityVectors,\n",
    "    distanceMetricEmbedding,\n",
    "    distanceMetric,\n",
    "    number_of_permutations,\n",
    "    ngramms,\n",
    "    jaccard_withchars,\n",
    "    prototypesFilterThr,\n",
    "    earlyStop=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_numberOf_clusters= [100,500,1000]\n",
    "max_dissimilarityDistance= [0.7,0.8]\n",
    "prototypesFilterThr = [0.2,0.3]\n",
    "\n",
    "distanceMetric= ['jaccard']\n",
    "\n",
    "\n",
    "ngramms= [2,3]  \n",
    "jaccard_withchars = [True] \n",
    "\n",
    "# ---------------- #\n",
    "\n",
    "distanceMetricEmbedding = ['euclidean']\n",
    "\n",
    "windowSize= [50]\n",
    "number_of_permutations = [5]\n",
    "\n",
    "similarityThreshold= [0.7]\n",
    "similarityVectors= ['ranked']\n",
    "metric= ['kendal']\n",
    "\n",
    "\n",
    "results_section1_jac = GridSearch_cora(\n",
    "    data,true_matrix,\n",
    "    max_numberOf_clusters,\n",
    "    max_dissimilarityDistance,\n",
    "    similarityThreshold,\n",
    "    windowSize,\n",
    "    metric,\n",
    "    similarityVectors,\n",
    "    distanceMetricEmbedding,\n",
    "    distanceMetric,\n",
    "    number_of_permutations,\n",
    "    ngramms,\n",
    "    jaccard_withchars,\n",
    "    prototypesFilterThr,\n",
    "    earlyStop=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### [iii] Fine tunning  __WTA algorithm__\n",
    "\n",
    "\n",
    "Goals:\n",
    "\n",
    "- __Ranked vectors dimension__\n",
    "- __Permutations__: A number of permutations will be forced in order to better split data into buckets.\n",
    "\n",
    " \n",
    "Parameters to fine tunne:\n",
    "\n",
    "- ```windowSize```: Vector size after WTA\n",
    "- ```number_of_permutations```: How many times vectors will be permuted and hashed\n",
    "\n",
    "All these parameters will be tested both for edit distance and jaccard with 3-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [iv] Fine tunning  __Similarity checking__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Various similarity metrics to check\n",
    "These functions are for the similarity checking phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Spearman footrule distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spearman_footrule_distance(s,t):\n",
    "    \"\"\"\n",
    "    Computes the Spearman footrule distance between two full lists of ranks:\n",
    "        F(s,t) = sum[ |s(i) - t(i)| ]/S,\n",
    "    the normalized sum over all elements in a set of the absolute difference between\n",
    "    the rank according to s and t.  As defined, 0 <= F(s,t) <= 1.\n",
    "    S is a normalizer which is equal to 0.5*len(s)^2 for even length ranklists and\n",
    "    0.5*(len(s)^2 - 1) for odd length ranklists.\n",
    "    If s,t are *not* full, this function should not be used. s,t should be array-like\n",
    "    (lists are OK).\n",
    "    \"\"\"\n",
    "    # check that size of intersection = size of s,t?\n",
    "    assert len(s) == len(t)\n",
    "    sdist = sum(abs(s - t))\n",
    "    # c will be 1 for odd length lists and 0 for even ones\n",
    "    c = len(s) % 2\n",
    "    normalizer = 0.5*(len(s)**2 - c)\n",
    "    \n",
    "    return sdist/normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ravi Kumar generalized Kendall Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kendall_top_k(a,b,k=None,p=0): #zero is equal 1 is max distance, compare with 1-scipy.stats.kendalltau(a,b)/2+1/2\n",
    "    \"\"\"\n",
    "    kendall_top_k(np.array,np.array,k,p)\n",
    "    This function generalise kendall-tau as defined in [1] Fagin, Ronald, Ravi Kumar, and D. Sivakumar. \"Comparing top k lists.\" SIAM Journal on Discrete Mathematics 17.1 (2003): 134-160.\n",
    "    It returns a distance: 0 for identical (in the sense of top-k) lists and 1 if completely different.\n",
    "    Example:\n",
    "        Simply call it with two same-length arrays of ratings (or also rankings), length of the top elements k (default is the maximum length possible), and p (default is 0, see [1]) as parameters:\n",
    "            $ a = np.array([1,2,3,4,5])\n",
    "            $ b = np.array([5,4,3,2,1])\n",
    "            $ kendall_top_k(a,b,k=4)\n",
    "    \"\"\"\n",
    "\n",
    "    if k is None:\n",
    "        k = a.size\n",
    "    if a.size != b.size:\n",
    "        raise NameError('The two arrays need to have same lengths')\n",
    "    k = min(k,a.size)\n",
    "    a_top_k = np.argpartition(a,-k)[-k:]\n",
    "    b_top_k = np.argpartition(b,-k)[-k:]\n",
    "    common_items = np.intersect1d(a_top_k,b_top_k)\n",
    "    only_in_a = np.setdiff1d(a_top_k, common_items)\n",
    "    only_in_b = np.setdiff1d(b_top_k, common_items)\n",
    "    kendall = (1 - (stats.kendalltau(a[common_items], b[common_items])[0]/2+0.5)) * (common_items.size**2) #case 1\n",
    "    if np.isnan(kendall): # degenerate case with only one item (not defined by Kendall)\n",
    "        kendall = 0\n",
    "    for i in common_items: #case 2\n",
    "        for j in only_in_a:\n",
    "            if a[i] < a[j]:\n",
    "                kendall += 1\n",
    "        for j in only_in_b:\n",
    "            if b[i] < b[j]:\n",
    "                kendall += 1\n",
    "    kendall += 2*p * special.binom(k-common_items.size,2)     #case 4\n",
    "    kendall /= ((only_in_a.size + only_in_b.size + common_items.size)**2 ) #normalization\n",
    "    return kendall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rank Biased Overlap (RBO) \n",
    "Article: https://towardsdatascience.com/rbo-v-s-kendall-tau-to-compare-ranked-lists-of-items-8776c5182899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rbo(list1, list2, p=0.9):\n",
    "\n",
    "    # tail recursive helper function \n",
    "    def helper(ret, i, d):    \n",
    "        l1 = set(list1[:i]) if i < len(list1) else set(list1)\n",
    "        l2 = set(list2[:i]) if i < len(list2) else set(list2)\n",
    "        a_d = len(l1.intersection(l2))/i\n",
    "        term = math.pow(p, i) * a_d\n",
    "        \n",
    "        if d == i:\n",
    "           return ret + term\n",
    "    \n",
    "        return helper(ret + term, i + 1, d)\n",
    "\n",
    "    k = max(len(list1), len(list2))\n",
    "    x_k = len(set(list1).intersection(set(list2)))\n",
    "    summation = helper(0, 1, k)\n",
    "\n",
    "    return ((float(x_k)/k) * math.pow(p, k)) + ((1-p)/p * summation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Winner Takes All proposed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def WTA_similarity(vector1,vector2):\n",
    "    \n",
    "    PO=0\n",
    "    for i in range(0,len(vector1),1):\n",
    "        for j in range(0,i,1):\n",
    "            ij_1 = vector1[i] - vector1[j]\n",
    "            ij_2 = vector2[i] - vector2[j]\n",
    "            PO += WTA_Threshold(ij_1*ij_2)\n",
    "    return PO\n",
    "\n",
    "def WTA_Threshold(x):    \n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.similarityProb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.mapping_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [v] Model final fine tunning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "There are four ways to check if the predictions are right or wrong:\n",
    "- __TN__ / True Negative: the case was negative and predicted negative\n",
    "- __TP__ / True Positive: the case was positive and predicted positive\n",
    "- __FN__ / False Negative: the case was positive but predicted negative\n",
    "- __FP__ / False Positive: the case was negative but predicted positive\n",
    "\n",
    "__Precision — What percent of your predictions were correct?__\n",
    "\n",
    "\n",
    "Precision is the ability of a classifier not to label an instance positive that is actually negative. For each class, it is defined as the ratio of true positives to the sum of a true positive and false positive.\n",
    "Precision:- Accuracy of positive predictions.\n",
    "Precision = TP/(TP + FP)\n",
    "\n",
    "\n",
    "__Recall — What percent of the positive cases did you catch?__\n",
    "\n",
    "\n",
    "Recall is the ability of a classifier to find all positive instances. For each class it is defined as the ratio of true positives to the sum of true positives and false negatives.\n",
    "Recall:- Fraction of positives that were correctly identified.\n",
    "Recall = TP/(TP+FN)\n",
    "\n",
    "__F1 score — What percent of positive predictions were correct?__\n",
    "\n",
    "\n",
    "The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. F1 scores are lower than accuracy measures as they embed precision and recall into their computation. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy.\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "\n",
    "__Support__\n",
    "\n",
    "\n",
    "Support is the number of actual occurrences of the class in the specified dataset. Imbalanced support in the training data may indicate structural weaknesses in the reported scores of the classifier and could indicate the need for stratified sampling or rebalancing. Support doesn’t change between models but instead diagnoses the evaluation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_numberOf_clusters= [100,500,1000]\n",
    "max_dissimilarityDistance= [50,100]\n",
    "prototypesFilterThr = [20,40,70]\n",
    "\n",
    "distanceMetric= ['edit']\n",
    "\n",
    "ngramms= [3]  \n",
    "jaccard_withchars = [False] \n",
    "\n",
    "distanceMetricEmbedding = ['l_inf','euclidean']\n",
    "\n",
    "windowSize= [16,32,64,128]\n",
    "number_of_permutations = [1,4,8]\n",
    "\n",
    "similarityThreshold= [0.7,0.75,0.8]\n",
    "similarityVectors= ['initial','ranked']\n",
    "metric= ['kendal','customKendal']\n",
    "\n",
    "\n",
    "\n",
    "results_section1_edit = GridSearch_cora(\n",
    "    data,true_matrix,\n",
    "    max_numberOf_clusters,\n",
    "    max_dissimilarityDistance,\n",
    "    similarityThreshold,\n",
    "    windowSize,\n",
    "    metric,\n",
    "    similarityVectors,\n",
    "    distanceMetricEmbedding,\n",
    "    distanceMetric,\n",
    "    number_of_permutations,\n",
    "    ngramms,\n",
    "    jaccard_withchars,\n",
    "    prototypesFilterThr,\n",
    "    earlyStop=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1.   [The dissimilarity representation for pattern recognition, a tutorial\n",
    "Robert P.W. Duin and Elzbieta Pekalska Delft University of Technology, The Netherlands School of Computer Science, University of Manchester, United Kingdom](http://homepage.tudelft.nl/a9p19/presentations/DisRep_Tutorial_doc.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
